{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "original-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-reunion",
   "metadata": {},
   "source": [
    "The input consists in 60 features and we have a total of 355 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-colorado",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       AA_0        AA_1         AA_2         AA_3      AA_4        AA_5  \\\n",
      "0 -0.172409    7.667924 -1220.791304 -4840.323841 -3.594498   26.631613   \n",
      "1 -6.518054  170.704308   423.294162  -434.068272 -1.878524   13.100269   \n",
      "2 -0.136293    6.993067  2477.870447 -8385.579930  6.689322   30.528608   \n",
      "3  2.712016   14.120212 -6911.504584 -8078.546083 -4.870796  137.317839   \n",
      "4 -0.093258   32.958313 -6418.941496 -1436.092921 -0.182052    7.942547   \n",
      "\n",
      "          AA_6         AA_7      AA_8       AA_9  ...     BB_16     AA_min  \\\n",
      "0  4398.225000  4498.513705 -1.573383  31.851562  ...  0.940441 -14.240520   \n",
      "1 -2513.273963 -3758.839135 -0.159738   7.387870  ...  0.938525 -11.362966   \n",
      "2 -7526.167337  -146.073301 -0.862950  86.084658  ...  0.943649 -14.454794   \n",
      "3  -390.049552  3443.994469  3.965135  28.919154  ...  0.934364  -9.931874   \n",
      "4 -3734.477809  2064.468355 -1.225585  76.101379  ...  0.942109 -12.536374   \n",
      "\n",
      "     AA_max    AB_min    AB_max    BB_min    BB_max    T  rho  model  \n",
      "0  0.489413 -1.204009  0.060857  1.792210  2.543866  9.9  1.6      0  \n",
      "1  0.504025 -0.869977  0.078201  2.248872  2.896889  9.8  1.4      0  \n",
      "2  0.491803 -1.219235  0.061356  1.792477  2.540990  9.8  1.6      0  \n",
      "3  0.539272 -0.697804  0.100882  2.798117  3.370060  9.0  1.2      0  \n",
      "4  0.511304 -0.964642  0.079405  2.229118  2.895090  9.0  1.4      0  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "(355, 60)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('x.csv')\n",
    "print(X.head())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-incentive",
   "metadata": {},
   "source": [
    "We want to predict 27 floating point outputs from the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "apart-november",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     w_AA_0   t0_AA_0    a_AA_0    b_AA_0        w_AA_1   t0_AA_1    a_AA_1  \\\n",
      "0  0.228322  0.124018 -2.819082  2.334874  2.443147e-05  0.749883 -0.879182   \n",
      "1  0.204227  0.120999 -3.850469  2.939569  1.449764e-07  0.463015 -0.766732   \n",
      "2  0.165903  0.153179 -2.601448  4.541583  7.195028e-05  0.208255 -0.888788   \n",
      "3  0.214907  0.126567 -3.057595  2.388040  5.227315e-05  0.702713 -0.798578   \n",
      "4  0.184886  0.131262 -3.722373  2.427054  2.896326e-04  0.586674 -1.014061   \n",
      "\n",
      "     b_AA_1      c_AA        w_AB_0  ...      c_AB    w_BB_0   t0_BB_0  \\\n",
      "0  0.615354 -0.356599  1.563313e-05  ...  0.090925  0.053514  0.180889   \n",
      "1  0.126668 -0.093676  4.130925e-08  ... -1.502683  0.008121  0.247915   \n",
      "2  0.325474 -0.439259  8.650406e-06  ... -1.343909  0.000134  1.092953   \n",
      "3  0.295806 -0.342688  9.238257e-07  ...  0.120454  0.051447  0.187341   \n",
      "4  0.549101 -0.311859  4.344589e-06  ...  0.096659  0.038565  0.200575   \n",
      "\n",
      "     a_BB_0    b_BB_0        w_BB_1   t0_BB_1    a_BB_1    b_BB_1      c_BB  \n",
      "0 -2.383147  2.066276  1.286598e-05  0.822379 -0.895481  0.408330 -0.873173  \n",
      "1 -3.965760  2.831034 -5.282985e-06  1.076257 -0.624012  0.000089 -0.725932  \n",
      "2 -0.716537  0.744943  1.982133e-05  1.085617  0.071503  0.235511 -0.811406  \n",
      "3 -2.533704  2.225513  7.405511e-06  0.857886 -0.795877  0.512627 -0.869594  \n",
      "4 -3.090306  2.337483  9.504892e-07  0.687950 -0.877554  0.426058 -0.881485  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "(355, 27)\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('y.csv')\n",
    "print(y.head())\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cheap-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stable-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seventh-grocery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AA_1', 'AA_2', 'AA_3', 'AA_4', 'AA_5', 'AA_6', 'AA_7', 'AA_8', 'AA_9',\n",
      "       'AA_10', 'AA_11', 'AA_12', 'AA_13', 'AA_14', 'AA_15', 'AA_16', 'AB_0',\n",
      "       'AB_1', 'AB_2', 'AB_3', 'AB_4', 'AB_5', 'AB_6', 'AB_7', 'AB_8', 'AB_9',\n",
      "       'AB_10', 'AB_11', 'AB_12', 'AB_13', 'AB_14', 'AB_15', 'AB_16', 'BB_0',\n",
      "       'BB_1', 'BB_2', 'BB_3', 'BB_4', 'BB_5', 'BB_6', 'BB_7', 'BB_8', 'BB_9',\n",
      "       'BB_10', 'BB_11', 'BB_12', 'BB_13', 'BB_14', 'BB_15', 'BB_16', 'AA_min',\n",
      "       'AA_max', 'AB_min', 'AB_max', 'BB_min', 'BB_max', 'T', 'rho', 'model'],\n",
      "      dtype='object')\n",
      "Index(['t0_AA_0', 'a_AA_0', 'b_AA_0', 'w_AA_1', 't0_AA_1', 'a_AA_1', 'b_AA_1',\n",
      "       'c_AA', 'w_AB_0', 't0_AB_0', 'a_AB_0', 'b_AB_0', 'w_AB_1', 't0_AB_1',\n",
      "       'a_AB_1', 'b_AB_1', 'c_AB', 'w_BB_0', 't0_BB_0', 'a_BB_0', 'b_BB_0',\n",
      "       'w_BB_1', 't0_BB_1', 'a_BB_1', 'b_BB_1', 'c_BB'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.columns[1:]\n",
    "print(feature_names)\n",
    "output_names = y.columns[1:]\n",
    "print(output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "viral-worst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA_0</th>\n",
       "      <th>AA_1</th>\n",
       "      <th>AA_2</th>\n",
       "      <th>AA_3</th>\n",
       "      <th>AA_4</th>\n",
       "      <th>AA_5</th>\n",
       "      <th>AA_6</th>\n",
       "      <th>AA_7</th>\n",
       "      <th>AA_8</th>\n",
       "      <th>AA_9</th>\n",
       "      <th>...</th>\n",
       "      <th>BB_16</th>\n",
       "      <th>AA_min</th>\n",
       "      <th>AA_max</th>\n",
       "      <th>AB_min</th>\n",
       "      <th>AB_max</th>\n",
       "      <th>BB_min</th>\n",
       "      <th>BB_max</th>\n",
       "      <th>T</th>\n",
       "      <th>rho</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.098361</td>\n",
       "      <td>0.016860</td>\n",
       "      <td>0.499940</td>\n",
       "      <td>0.508982</td>\n",
       "      <td>0.527043</td>\n",
       "      <td>0.107893</td>\n",
       "      <td>0.482583</td>\n",
       "      <td>0.505710</td>\n",
       "      <td>0.737242</td>\n",
       "      <td>0.172327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642973</td>\n",
       "      <td>0.696916</td>\n",
       "      <td>0.512851</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.392591</td>\n",
       "      <td>0.554542</td>\n",
       "      <td>0.430080</td>\n",
       "      <td>0.176278</td>\n",
       "      <td>0.528169</td>\n",
       "      <td>0.478873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.284916</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.272656</td>\n",
       "      <td>0.269161</td>\n",
       "      <td>0.056506</td>\n",
       "      <td>0.140275</td>\n",
       "      <td>0.266214</td>\n",
       "      <td>0.269470</td>\n",
       "      <td>0.059337</td>\n",
       "      <td>0.230219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200354</td>\n",
       "      <td>0.169832</td>\n",
       "      <td>0.239524</td>\n",
       "      <td>0.216419</td>\n",
       "      <td>0.236833</td>\n",
       "      <td>0.185355</td>\n",
       "      <td>0.353242</td>\n",
       "      <td>0.192650</td>\n",
       "      <td>0.397762</td>\n",
       "      <td>0.500435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-929.851921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.782278</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.250466</td>\n",
       "      <td>0.272647</td>\n",
       "      <td>0.524377</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.272665</td>\n",
       "      <td>0.303352</td>\n",
       "      <td>0.742157</td>\n",
       "      <td>0.042538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581618</td>\n",
       "      <td>0.613180</td>\n",
       "      <td>0.353665</td>\n",
       "      <td>0.491559</td>\n",
       "      <td>0.233416</td>\n",
       "      <td>0.464111</td>\n",
       "      <td>0.054865</td>\n",
       "      <td>0.059067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.081263</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.497855</td>\n",
       "      <td>0.520427</td>\n",
       "      <td>0.524838</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.483961</td>\n",
       "      <td>0.493809</td>\n",
       "      <td>0.742618</td>\n",
       "      <td>0.084803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682798</td>\n",
       "      <td>0.717894</td>\n",
       "      <td>0.497455</td>\n",
       "      <td>0.672465</td>\n",
       "      <td>0.349684</td>\n",
       "      <td>0.565392</td>\n",
       "      <td>0.409365</td>\n",
       "      <td>0.129534</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.159065</td>\n",
       "      <td>0.009691</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.737534</td>\n",
       "      <td>0.525316</td>\n",
       "      <td>0.142618</td>\n",
       "      <td>0.703298</td>\n",
       "      <td>0.730145</td>\n",
       "      <td>0.743127</td>\n",
       "      <td>0.176202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778609</td>\n",
       "      <td>0.812441</td>\n",
       "      <td>0.631886</td>\n",
       "      <td>0.771009</td>\n",
       "      <td>0.540284</td>\n",
       "      <td>0.692229</td>\n",
       "      <td>0.885897</td>\n",
       "      <td>0.213731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1786.402041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AA_0        AA_1        AA_2        AA_3        AA_4  \\\n",
       "count   284.000000  284.000000  284.000000  284.000000  284.000000   \n",
       "mean     18.098361    0.016860    0.499940    0.508982    0.527043   \n",
       "std     171.284916    0.064559    0.272656    0.269161    0.056506   \n",
       "min    -929.851921    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      -1.782278    0.002921    0.250466    0.272647    0.524377   \n",
       "50%       0.081263    0.006490    0.497855    0.520427    0.524838   \n",
       "75%       2.159065    0.009691    0.718075    0.737534    0.525316   \n",
       "max    1786.402041    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             AA_5        AA_6        AA_7        AA_8        AA_9  ...  \\\n",
       "count  284.000000  284.000000  284.000000  284.000000  284.000000  ...   \n",
       "mean     0.107893    0.482583    0.505710    0.737242    0.172327  ...   \n",
       "std      0.140275    0.266214    0.269470    0.059337    0.230219  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.010802    0.272665    0.303352    0.742157    0.042538  ...   \n",
       "50%      0.050072    0.483961    0.493809    0.742618    0.084803  ...   \n",
       "75%      0.142618    0.703298    0.730145    0.743127    0.176202  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "            BB_16      AA_min      AA_max      AB_min      AB_max      BB_min  \\\n",
       "count  284.000000  284.000000  284.000000  284.000000  284.000000  284.000000   \n",
       "mean     0.642973    0.696916    0.512851    0.621600    0.392591    0.554542   \n",
       "std      0.200354    0.169832    0.239524    0.216419    0.236833    0.185355   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.581618    0.613180    0.353665    0.491559    0.233416    0.464111   \n",
       "50%      0.682798    0.717894    0.497455    0.672465    0.349684    0.565392   \n",
       "75%      0.778609    0.812441    0.631886    0.771009    0.540284    0.692229   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "           BB_max           T         rho       model  \n",
       "count  284.000000  284.000000  284.000000  284.000000  \n",
       "mean     0.430080    0.176278    0.528169    0.478873  \n",
       "std      0.353242    0.192650    0.397762    0.500435  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.054865    0.059067    0.000000    0.000000  \n",
       "50%      0.409365    0.129534    0.500000    0.000000  \n",
       "75%      0.885897    0.213731    1.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[feature_names] = min_max_scaler.fit_transform(X_train[feature_names])\n",
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loaded-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[feature_names] = min_max_scaler.fit_transform(X_test[feature_names])\n",
    "\n",
    "y_test_scaled = y_test.copy()\n",
    "y_test_scaled[output_names] = min_max_scaler.fit_transform(y_test[output_names])\n",
    "\n",
    "y_train_scaled = y_train.copy()\n",
    "y_train_scaled[output_names] = min_max_scaler.fit_transform(y_train[output_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "german-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor(hidden_layer_sizes=(100,100), activation='relu', solver='lbfgs', alpha=0.001, batch_size='auto',\n",
    "                     learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=100000, \n",
    "                     shuffle=True, random_state=666, tol=0.0001, verbose=True, warm_start=False, \n",
    "                     momentum=0.9, nesterovs_momentum=True, early_stopping=False, \n",
    "                     beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=150000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "falling-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#parameter_space = {\n",
    "#    #'activation': ['tanh', 'relu'],\n",
    "#    'alpha': [0.0001, 0.001, 0.05],\n",
    "#    'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,),\n",
    "#                           (100, 100), (100, 100, 100), (50,)],\n",
    "#    'n_iter_no_change': [10, 100, 1000],\n",
    "#    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "#    'tol': [10**-3,10 ** -4, 10 ** -5],\n",
    "#}\n",
    "#print(\"Creating GridSearchCV object\")\n",
    "#model = GridSearchCV(model, parameter_space, n_jobs=4, cv=3)\n",
    "#print(\"Starting Grid Search (WARNING: this may take a VERY long time)\")\n",
    "#model.fit(X_train_scaled,y_train_scaled)\n",
    "#print(\"Finished Grid Search\")\n",
    "\n",
    "# Best parameter set\n",
    "#print('Best parameters found:\\n', clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unavailable-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have found the best parameters using the grid search above\n",
    "# here they are:\n",
    "model = MLPRegressor(hidden_layer_sizes=(80,80), activation='relu', solver='adam', alpha=0.0001, batch_size='auto',\n",
    "                     learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=1000000, \n",
    "                     shuffle=True, random_state=666, tol=1e-8, verbose=True, warm_start=False, \n",
    "                     momentum=0.9, nesterovs_momentum=True, early_stopping=True, \n",
    "                     beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=1000, max_fun=150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fantastic-landing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 100.51615121\n",
      "Validation score: -1853.453536\n",
      "Iteration 2, loss = 75.47904047\n",
      "Validation score: -1382.548602\n",
      "Iteration 3, loss = 56.54738763\n",
      "Validation score: -1069.500897\n",
      "Iteration 4, loss = 41.87907261\n",
      "Validation score: -859.634234\n",
      "Iteration 5, loss = 31.98078401\n",
      "Validation score: -704.124681\n",
      "Iteration 6, loss = 24.41812996\n",
      "Validation score: -574.640586\n",
      "Iteration 7, loss = 18.30140178\n",
      "Validation score: -468.229871\n",
      "Iteration 8, loss = 13.88391436\n",
      "Validation score: -375.271480\n",
      "Iteration 9, loss = 9.22342900\n",
      "Validation score: -289.788743\n",
      "Iteration 10, loss = 7.19359661\n",
      "Validation score: -203.116108\n",
      "Iteration 11, loss = 5.12861310\n",
      "Validation score: -142.305877\n",
      "Iteration 12, loss = 3.57515944\n",
      "Validation score: -101.811101\n",
      "Iteration 13, loss = 2.36113857\n",
      "Validation score: -73.108239\n",
      "Iteration 14, loss = 1.85540104\n",
      "Validation score: -50.556817\n",
      "Iteration 15, loss = 1.26012441\n",
      "Validation score: -35.602473\n",
      "Iteration 16, loss = 0.86762169\n",
      "Validation score: -24.640146\n",
      "Iteration 17, loss = 0.60992807\n",
      "Validation score: -18.275465\n",
      "Iteration 18, loss = 0.43512196\n",
      "Validation score: -14.528385\n",
      "Iteration 19, loss = 0.31572232\n",
      "Validation score: -12.413477\n",
      "Iteration 20, loss = 0.25247255\n",
      "Validation score: -11.519018\n",
      "Iteration 21, loss = 0.22942420\n",
      "Validation score: -11.001984\n",
      "Iteration 22, loss = 0.22155105\n",
      "Validation score: -10.411905\n",
      "Iteration 23, loss = 0.21884080\n",
      "Validation score: -10.430157\n",
      "Iteration 24, loss = 0.21300276\n",
      "Validation score: -10.039617\n",
      "Iteration 25, loss = 0.19387520\n",
      "Validation score: -9.625920\n",
      "Iteration 26, loss = 0.17091898\n",
      "Validation score: -9.592770\n",
      "Iteration 27, loss = 0.15112477\n",
      "Validation score: -8.918081\n",
      "Iteration 28, loss = 0.13196016\n",
      "Validation score: -7.727786\n",
      "Iteration 29, loss = 0.11199840\n",
      "Validation score: -7.109039\n",
      "Iteration 30, loss = 0.09423254\n",
      "Validation score: -6.607167\n",
      "Iteration 31, loss = 0.08192225\n",
      "Validation score: -5.731584\n",
      "Iteration 32, loss = 0.06876560\n",
      "Validation score: -5.160858\n",
      "Iteration 33, loss = 0.06348259\n",
      "Validation score: -4.978288\n",
      "Iteration 34, loss = 0.05758698\n",
      "Validation score: -4.722881\n",
      "Iteration 35, loss = 0.05296791\n",
      "Validation score: -4.510783\n",
      "Iteration 36, loss = 0.04951104\n",
      "Validation score: -4.295928\n",
      "Iteration 37, loss = 0.04409743\n",
      "Validation score: -4.177648\n",
      "Iteration 38, loss = 0.04010328\n",
      "Validation score: -3.977911\n",
      "Iteration 39, loss = 0.03651216\n",
      "Validation score: -3.725668\n",
      "Iteration 40, loss = 0.03396523\n",
      "Validation score: -3.575874\n",
      "Iteration 41, loss = 0.03213942\n",
      "Validation score: -3.549218\n",
      "Iteration 42, loss = 0.03036056\n",
      "Validation score: -3.513984\n",
      "Iteration 43, loss = 0.02932653\n",
      "Validation score: -3.296255\n",
      "Iteration 44, loss = 0.02768026\n",
      "Validation score: -3.143530\n",
      "Iteration 45, loss = 0.02883236\n",
      "Validation score: -3.025135\n",
      "Iteration 46, loss = 0.02714858\n",
      "Validation score: -2.970607\n",
      "Iteration 47, loss = 0.02626432\n",
      "Validation score: -2.903711\n",
      "Iteration 48, loss = 0.02642086\n",
      "Validation score: -3.305113\n",
      "Iteration 49, loss = 0.03915765\n",
      "Validation score: -2.584496\n",
      "Iteration 50, loss = 0.02579835\n",
      "Validation score: -2.487107\n",
      "Iteration 51, loss = 0.02462235\n",
      "Validation score: -2.373400\n",
      "Iteration 52, loss = 0.02574440\n",
      "Validation score: -2.253573\n",
      "Iteration 53, loss = 0.02476056\n",
      "Validation score: -2.115059\n",
      "Iteration 54, loss = 0.02258452\n",
      "Validation score: -2.068448\n",
      "Iteration 55, loss = 0.02278414\n",
      "Validation score: -2.034052\n",
      "Iteration 56, loss = 0.02260565\n",
      "Validation score: -1.924353\n",
      "Iteration 57, loss = 0.02181765\n",
      "Validation score: -1.798684\n",
      "Iteration 58, loss = 0.02150017\n",
      "Validation score: -1.721246\n",
      "Iteration 59, loss = 0.02156743\n",
      "Validation score: -1.704802\n",
      "Iteration 60, loss = 0.02080012\n",
      "Validation score: -1.743934\n",
      "Iteration 61, loss = 0.02073087\n",
      "Validation score: -1.633718\n",
      "Iteration 62, loss = 0.01980782\n",
      "Validation score: -1.523014\n",
      "Iteration 63, loss = 0.02083954\n",
      "Validation score: -1.472346\n",
      "Iteration 64, loss = 0.01960615\n",
      "Validation score: -1.558585\n",
      "Iteration 65, loss = 0.02087170\n",
      "Validation score: -1.491203\n",
      "Iteration 66, loss = 0.02057836\n",
      "Validation score: -1.316651\n",
      "Iteration 67, loss = 0.01959265\n",
      "Validation score: -1.249734\n",
      "Iteration 68, loss = 0.01900953\n",
      "Validation score: -1.263948\n",
      "Iteration 69, loss = 0.01923110\n",
      "Validation score: -1.233400\n",
      "Iteration 70, loss = 0.01923069\n",
      "Validation score: -1.163002\n",
      "Iteration 71, loss = 0.01870632\n",
      "Validation score: -1.125743\n",
      "Iteration 72, loss = 0.01839202\n",
      "Validation score: -1.103563\n",
      "Iteration 73, loss = 0.01840797\n",
      "Validation score: -1.067160\n",
      "Iteration 74, loss = 0.01803129\n",
      "Validation score: -1.028437\n",
      "Iteration 75, loss = 0.01799755\n",
      "Validation score: -0.988133\n",
      "Iteration 76, loss = 0.01785237\n",
      "Validation score: -0.970041\n",
      "Iteration 77, loss = 0.01759159\n",
      "Validation score: -0.967286\n",
      "Iteration 78, loss = 0.01771444\n",
      "Validation score: -0.943011\n",
      "Iteration 79, loss = 0.01775774\n",
      "Validation score: -0.916744\n",
      "Iteration 80, loss = 0.01751159\n",
      "Validation score: -0.916135\n",
      "Iteration 81, loss = 0.01734683\n",
      "Validation score: -0.945907\n",
      "Iteration 82, loss = 0.01755665\n",
      "Validation score: -0.911950\n",
      "Iteration 83, loss = 0.01713738\n",
      "Validation score: -0.878054\n",
      "Iteration 84, loss = 0.01717760\n",
      "Validation score: -0.875514\n",
      "Iteration 85, loss = 0.01706441\n",
      "Validation score: -0.850177\n",
      "Iteration 86, loss = 0.01684547\n",
      "Validation score: -0.843079\n",
      "Iteration 87, loss = 0.01692186\n",
      "Validation score: -0.817208\n",
      "Iteration 88, loss = 0.01679837\n",
      "Validation score: -0.796743\n",
      "Iteration 89, loss = 0.01670991\n",
      "Validation score: -0.780892\n",
      "Iteration 90, loss = 0.01651643\n",
      "Validation score: -0.780366\n",
      "Iteration 91, loss = 0.01650512\n",
      "Validation score: -0.780283\n",
      "Iteration 92, loss = 0.01651087\n",
      "Validation score: -0.764924\n",
      "Iteration 93, loss = 0.01643527\n",
      "Validation score: -0.755574\n",
      "Iteration 94, loss = 0.01627030\n",
      "Validation score: -0.767920\n",
      "Iteration 95, loss = 0.01653852\n",
      "Validation score: -0.740514\n",
      "Iteration 96, loss = 0.01614976\n",
      "Validation score: -0.725669\n",
      "Iteration 97, loss = 0.01605900\n",
      "Validation score: -0.729054\n",
      "Iteration 98, loss = 0.01610549\n",
      "Validation score: -0.721824\n",
      "Iteration 99, loss = 0.01611832\n",
      "Validation score: -0.701986\n",
      "Iteration 100, loss = 0.01595798\n",
      "Validation score: -0.689731\n",
      "Iteration 101, loss = 0.01584140\n",
      "Validation score: -0.691512\n",
      "Iteration 102, loss = 0.01597219\n",
      "Validation score: -0.705253\n",
      "Iteration 103, loss = 0.01602630\n",
      "Validation score: -0.666963\n",
      "Iteration 104, loss = 0.01585356\n",
      "Validation score: -0.658218\n",
      "Iteration 105, loss = 0.01778853\n",
      "Validation score: -0.757289\n",
      "Iteration 106, loss = 0.01680491\n",
      "Validation score: -1.345111\n",
      "Iteration 107, loss = 0.02965071\n",
      "Validation score: -0.905215\n",
      "Iteration 108, loss = 0.01930786\n",
      "Validation score: -0.685703\n",
      "Iteration 109, loss = 0.02140278\n",
      "Validation score: -0.642715\n",
      "Iteration 110, loss = 0.01726894\n",
      "Validation score: -0.849627\n",
      "Iteration 111, loss = 0.01961633\n",
      "Validation score: -0.797450\n",
      "Iteration 112, loss = 0.01755538\n",
      "Validation score: -0.688680\n",
      "Iteration 113, loss = 0.01920601\n",
      "Validation score: -0.670634\n",
      "Iteration 114, loss = 0.01982917\n",
      "Validation score: -0.621150\n",
      "Iteration 115, loss = 0.01576447\n",
      "Validation score: -0.982201\n",
      "Iteration 116, loss = 0.02354921\n",
      "Validation score: -0.726611\n",
      "Iteration 117, loss = 0.01646703\n",
      "Validation score: -0.642200\n",
      "Iteration 118, loss = 0.01929429\n",
      "Validation score: -0.659009\n",
      "Iteration 119, loss = 0.02099717\n",
      "Validation score: -0.687873\n",
      "Iteration 120, loss = 0.01745704\n",
      "Validation score: -0.690044\n",
      "Iteration 121, loss = 0.01664433\n",
      "Validation score: -0.657000\n",
      "Iteration 122, loss = 0.01545755\n",
      "Validation score: -0.574498\n",
      "Iteration 123, loss = 0.01548916\n",
      "Validation score: -0.578142\n",
      "Iteration 124, loss = 0.01663012\n",
      "Validation score: -0.569901\n",
      "Iteration 125, loss = 0.01523532\n",
      "Validation score: -0.620378\n",
      "Iteration 126, loss = 0.01509357\n",
      "Validation score: -0.654736\n",
      "Iteration 127, loss = 0.01551057\n",
      "Validation score: -0.595054\n",
      "Iteration 128, loss = 0.01477476\n",
      "Validation score: -0.556057\n",
      "Iteration 129, loss = 0.01566436\n",
      "Validation score: -0.556758\n",
      "Iteration 130, loss = 0.01468919\n",
      "Validation score: -0.603647\n",
      "Iteration 131, loss = 0.01502437\n",
      "Validation score: -0.578242\n",
      "Iteration 132, loss = 0.01458943\n",
      "Validation score: -0.543461\n",
      "Iteration 133, loss = 0.01477020\n",
      "Validation score: -0.542393\n",
      "Iteration 134, loss = 0.01487032\n",
      "Validation score: -0.552641\n",
      "Iteration 135, loss = 0.01451883\n",
      "Validation score: -0.597016\n",
      "Iteration 136, loss = 0.01504574\n",
      "Validation score: -0.567479\n",
      "Iteration 137, loss = 0.01446408\n",
      "Validation score: -0.538152\n",
      "Iteration 138, loss = 0.01493400\n",
      "Validation score: -0.533661\n",
      "Iteration 139, loss = 0.01483451\n",
      "Validation score: -0.566147\n",
      "Iteration 140, loss = 0.01475429\n",
      "Validation score: -0.542704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 141, loss = 0.01560681\n",
      "Validation score: -0.533096\n",
      "Iteration 142, loss = 0.01517187\n",
      "Validation score: -0.517519\n",
      "Iteration 143, loss = 0.01954705\n",
      "Validation score: -0.528328\n",
      "Iteration 144, loss = 0.01714519\n",
      "Validation score: -0.602379\n",
      "Iteration 145, loss = 0.01711500\n",
      "Validation score: -0.532170\n",
      "Iteration 146, loss = 0.01442421\n",
      "Validation score: -0.510710\n",
      "Iteration 147, loss = 0.01750934\n",
      "Validation score: -0.498069\n",
      "Iteration 148, loss = 0.01824958\n",
      "Validation score: -0.490397\n",
      "Iteration 149, loss = 0.01424287\n",
      "Validation score: -0.568899\n",
      "Iteration 150, loss = 0.01605729\n",
      "Validation score: -0.560336\n",
      "Iteration 151, loss = 0.01489042\n",
      "Validation score: -0.483131\n",
      "Iteration 152, loss = 0.01561391\n",
      "Validation score: -0.473653\n",
      "Iteration 153, loss = 0.01646352\n",
      "Validation score: -0.492087\n",
      "Iteration 154, loss = 0.01411000\n",
      "Validation score: -0.565575\n",
      "Iteration 155, loss = 0.01520841\n",
      "Validation score: -0.516379\n",
      "Iteration 156, loss = 0.01518080\n",
      "Validation score: -0.463990\n",
      "Iteration 157, loss = 0.01459838\n",
      "Validation score: -0.459137\n",
      "Iteration 158, loss = 0.01388365\n",
      "Validation score: -0.490139\n",
      "Iteration 159, loss = 0.01459274\n",
      "Validation score: -0.496687\n",
      "Iteration 160, loss = 0.01430623\n",
      "Validation score: -0.454392\n",
      "Iteration 161, loss = 0.01394317\n",
      "Validation score: -0.443749\n",
      "Iteration 162, loss = 0.01411696\n",
      "Validation score: -0.470346\n",
      "Iteration 163, loss = 0.01379510\n",
      "Validation score: -0.617664\n",
      "Iteration 164, loss = 0.01729971\n",
      "Validation score: -0.469116\n",
      "Iteration 165, loss = 0.01412492\n",
      "Validation score: -0.564878\n",
      "Iteration 166, loss = 0.02021778\n",
      "Validation score: -0.526122\n",
      "Iteration 167, loss = 0.01795907\n",
      "Validation score: -0.451505\n",
      "Iteration 168, loss = 0.01419391\n",
      "Validation score: -0.787907\n",
      "Iteration 169, loss = 0.02147727\n",
      "Validation score: -0.599775\n",
      "Iteration 170, loss = 0.01691455\n",
      "Validation score: -0.431779\n",
      "Iteration 171, loss = 0.01446187\n",
      "Validation score: -0.489775\n",
      "Iteration 172, loss = 0.01761809\n",
      "Validation score: -0.419373\n",
      "Iteration 173, loss = 0.01441109\n",
      "Validation score: -0.505770\n",
      "Iteration 174, loss = 0.01483540\n",
      "Validation score: -0.558180\n",
      "Iteration 175, loss = 0.01588247\n",
      "Validation score: -0.440350\n",
      "Iteration 176, loss = 0.01347939\n",
      "Validation score: -0.418482\n",
      "Iteration 177, loss = 0.01432631\n",
      "Validation score: -0.412060\n",
      "Iteration 178, loss = 0.01437129\n",
      "Validation score: -0.410280\n",
      "Iteration 179, loss = 0.01344621\n",
      "Validation score: -0.435467\n",
      "Iteration 180, loss = 0.01346939\n",
      "Validation score: -0.417216\n",
      "Iteration 181, loss = 0.01334974\n",
      "Validation score: -0.402805\n",
      "Iteration 182, loss = 0.01339230\n",
      "Validation score: -0.400968\n",
      "Iteration 183, loss = 0.01336946\n",
      "Validation score: -0.409266\n",
      "Iteration 184, loss = 0.01328035\n",
      "Validation score: -0.409598\n",
      "Iteration 185, loss = 0.01324285\n",
      "Validation score: -0.403570\n",
      "Iteration 186, loss = 0.01331130\n",
      "Validation score: -0.397318\n",
      "Iteration 187, loss = 0.01335166\n",
      "Validation score: -0.393799\n",
      "Iteration 188, loss = 0.01324736\n",
      "Validation score: -0.395017\n",
      "Iteration 189, loss = 0.01317717\n",
      "Validation score: -0.391886\n",
      "Iteration 190, loss = 0.01312300\n",
      "Validation score: -0.391520\n",
      "Iteration 191, loss = 0.01316951\n",
      "Validation score: -0.390432\n",
      "Iteration 192, loss = 0.01307463\n",
      "Validation score: -0.391665\n",
      "Iteration 193, loss = 0.01316019\n",
      "Validation score: -0.387616\n",
      "Iteration 194, loss = 0.01310916\n",
      "Validation score: -0.386236\n",
      "Iteration 195, loss = 0.01307997\n",
      "Validation score: -0.386730\n",
      "Iteration 196, loss = 0.01300405\n",
      "Validation score: -0.386332\n",
      "Iteration 197, loss = 0.01306278\n",
      "Validation score: -0.384766\n",
      "Iteration 198, loss = 0.01298026\n",
      "Validation score: -0.380374\n",
      "Iteration 199, loss = 0.01311032\n",
      "Validation score: -0.380786\n",
      "Iteration 200, loss = 0.01312116\n",
      "Validation score: -0.380270\n",
      "Iteration 201, loss = 0.01294805\n",
      "Validation score: -0.375523\n",
      "Iteration 202, loss = 0.01357981\n",
      "Validation score: -0.377726\n",
      "Iteration 203, loss = 0.01334447\n",
      "Validation score: -0.388421\n",
      "Iteration 204, loss = 0.01304425\n",
      "Validation score: -0.382139\n",
      "Iteration 205, loss = 0.01320906\n",
      "Validation score: -0.369541\n",
      "Iteration 206, loss = 0.01286740\n",
      "Validation score: -0.368367\n",
      "Iteration 207, loss = 0.01429441\n",
      "Validation score: -0.380684\n",
      "Iteration 208, loss = 0.01365582\n",
      "Validation score: -0.379893\n",
      "Iteration 209, loss = 0.01365113\n",
      "Validation score: -0.371176\n",
      "Iteration 210, loss = 0.01289221\n",
      "Validation score: -0.366971\n",
      "Iteration 211, loss = 0.01787087\n",
      "Validation score: -0.382035\n",
      "Iteration 212, loss = 0.01313934\n",
      "Validation score: -0.422946\n",
      "Iteration 213, loss = 0.03298255\n",
      "Validation score: -0.400165\n",
      "Iteration 214, loss = 0.03210065\n",
      "Validation score: -0.366968\n",
      "Iteration 215, loss = 0.01479153\n",
      "Validation score: -0.364708\n",
      "Iteration 216, loss = 0.01475223\n",
      "Validation score: -0.396042\n",
      "Iteration 217, loss = 0.01962029\n",
      "Validation score: -0.382417\n",
      "Iteration 218, loss = 0.01819666\n",
      "Validation score: -0.370266\n",
      "Iteration 219, loss = 0.01510659\n",
      "Validation score: -0.401385\n",
      "Iteration 220, loss = 0.01531703\n",
      "Validation score: -0.494295\n",
      "Iteration 221, loss = 0.01782559\n",
      "Validation score: -0.413098\n",
      "Iteration 222, loss = 0.01532180\n",
      "Validation score: -0.370047\n",
      "Iteration 223, loss = 0.01436564\n",
      "Validation score: -0.363181\n",
      "Iteration 224, loss = 0.01430310\n",
      "Validation score: -0.365398\n",
      "Iteration 225, loss = 0.01374259\n",
      "Validation score: -0.391229\n",
      "Iteration 226, loss = 0.01404171\n",
      "Validation score: -0.377110\n",
      "Iteration 227, loss = 0.01386913\n",
      "Validation score: -0.486009\n",
      "Iteration 228, loss = 0.01778586\n",
      "Validation score: -0.377799\n",
      "Iteration 229, loss = 0.01364509\n",
      "Validation score: -0.826543\n",
      "Iteration 230, loss = 0.02553800\n",
      "Validation score: -0.498663\n",
      "Iteration 231, loss = 0.01581663\n",
      "Validation score: -0.473614\n",
      "Iteration 232, loss = 0.02105258\n",
      "Validation score: -0.431203\n",
      "Iteration 233, loss = 0.01692985\n",
      "Validation score: -1.797290\n",
      "Iteration 234, loss = 0.05555907\n",
      "Validation score: -0.654124\n",
      "Iteration 235, loss = 0.01929646\n",
      "Validation score: -1.052553\n",
      "Iteration 236, loss = 0.03619836\n",
      "Validation score: -1.116763\n",
      "Iteration 237, loss = 0.03981839\n",
      "Validation score: -0.378728\n",
      "Iteration 238, loss = 0.01437458\n",
      "Validation score: -0.842881\n",
      "Iteration 239, loss = 0.02901048\n",
      "Validation score: -0.477176\n",
      "Iteration 240, loss = 0.01564633\n",
      "Validation score: -0.589776\n",
      "Iteration 241, loss = 0.01923116\n",
      "Validation score: -0.526764\n",
      "Iteration 242, loss = 0.01779123\n",
      "Validation score: -0.369239\n",
      "Iteration 243, loss = 0.01339302\n",
      "Validation score: -0.736255\n",
      "Iteration 244, loss = 0.02311606\n",
      "Validation score: -0.560565\n",
      "Iteration 245, loss = 0.01798416\n",
      "Validation score: -0.409076\n",
      "Iteration 246, loss = 0.01583899\n",
      "Validation score: -0.426352\n",
      "Iteration 247, loss = 0.01526995\n",
      "Validation score: -0.392758\n",
      "Iteration 248, loss = 0.01440808\n",
      "Validation score: -0.461329\n",
      "Iteration 249, loss = 0.01471633\n",
      "Validation score: -0.366245\n",
      "Iteration 250, loss = 0.01319034\n",
      "Validation score: -0.439917\n",
      "Iteration 251, loss = 0.01536717\n",
      "Validation score: -0.380492\n",
      "Iteration 252, loss = 0.01379104\n",
      "Validation score: -0.373753\n",
      "Iteration 253, loss = 0.01443639\n",
      "Validation score: -0.393467\n",
      "Iteration 254, loss = 0.01371548\n",
      "Validation score: -0.356611\n",
      "Iteration 255, loss = 0.01285287\n",
      "Validation score: -0.385416\n",
      "Iteration 256, loss = 0.01379619\n",
      "Validation score: -0.346838\n",
      "Iteration 257, loss = 0.01244065\n",
      "Validation score: -0.496900\n",
      "Iteration 258, loss = 0.01639219\n",
      "Validation score: -0.430423\n",
      "Iteration 259, loss = 0.01482747\n",
      "Validation score: -0.328256\n",
      "Iteration 260, loss = 0.01291674\n",
      "Validation score: -0.349604\n",
      "Iteration 261, loss = 0.01309317\n",
      "Validation score: -0.370573\n",
      "Iteration 262, loss = 0.01263794\n",
      "Validation score: -0.389762\n",
      "Iteration 263, loss = 0.01307670\n",
      "Validation score: -0.332804\n",
      "Iteration 264, loss = 0.01251467\n",
      "Validation score: -0.366283\n",
      "Iteration 265, loss = 0.01447811\n",
      "Validation score: -0.330978\n",
      "Iteration 266, loss = 0.01336301\n",
      "Validation score: -0.368867\n",
      "Iteration 267, loss = 0.01388434\n",
      "Validation score: -0.354296\n",
      "Iteration 268, loss = 0.01299932\n",
      "Validation score: -0.337994\n",
      "Iteration 269, loss = 0.01268405\n",
      "Validation score: -0.344314\n",
      "Iteration 270, loss = 0.01266344\n",
      "Validation score: -0.386935\n",
      "Iteration 271, loss = 0.01324110\n",
      "Validation score: -0.363425\n",
      "Iteration 272, loss = 0.01273664\n",
      "Validation score: -0.318353\n",
      "Iteration 273, loss = 0.01333779\n",
      "Validation score: -0.321147\n",
      "Iteration 274, loss = 0.01315585\n",
      "Validation score: -0.380929\n",
      "Iteration 275, loss = 0.01288859\n",
      "Validation score: -0.379424\n",
      "Iteration 276, loss = 0.01258177\n",
      "Validation score: -0.333773\n",
      "Iteration 277, loss = 0.01308877\n",
      "Validation score: -0.336104\n",
      "Iteration 278, loss = 0.01268830\n",
      "Validation score: -0.415235\n",
      "Iteration 279, loss = 0.01374178\n",
      "Validation score: -0.356449\n",
      "Iteration 280, loss = 0.01232665\n",
      "Validation score: -0.321426\n",
      "Iteration 281, loss = 0.01260045\n",
      "Validation score: -0.323065\n",
      "Iteration 282, loss = 0.01295705\n",
      "Validation score: -0.324196\n",
      "Iteration 283, loss = 0.01205242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: -0.355865\n",
      "Iteration 284, loss = 0.01258619\n",
      "Validation score: -0.341202\n",
      "Iteration 285, loss = 0.01212466\n",
      "Validation score: -0.310524\n",
      "Iteration 286, loss = 0.01245987\n",
      "Validation score: -0.307174\n",
      "Iteration 287, loss = 0.01262370\n",
      "Validation score: -0.320627\n",
      "Iteration 288, loss = 0.01211299\n",
      "Validation score: -0.329209\n",
      "Iteration 289, loss = 0.01209719\n",
      "Validation score: -0.313019\n",
      "Iteration 290, loss = 0.01226927\n",
      "Validation score: -0.307216\n",
      "Iteration 291, loss = 0.01221634\n",
      "Validation score: -0.303040\n",
      "Iteration 292, loss = 0.01278441\n",
      "Validation score: -0.306796\n",
      "Iteration 293, loss = 0.01307066\n",
      "Validation score: -0.333543\n",
      "Iteration 294, loss = 0.01244969\n",
      "Validation score: -0.333461\n",
      "Iteration 295, loss = 0.01207344\n",
      "Validation score: -0.327459\n",
      "Iteration 296, loss = 0.01302545\n",
      "Validation score: -0.307245\n",
      "Iteration 297, loss = 0.01253433\n",
      "Validation score: -0.305997\n",
      "Iteration 298, loss = 0.01207225\n",
      "Validation score: -0.308674\n",
      "Iteration 299, loss = 0.01451991\n",
      "Validation score: -0.302719\n",
      "Iteration 300, loss = 0.01427983\n",
      "Validation score: -0.306033\n",
      "Iteration 301, loss = 0.01236231\n",
      "Validation score: -0.313004\n",
      "Iteration 302, loss = 0.01267556\n",
      "Validation score: -0.318214\n",
      "Iteration 303, loss = 0.01359600\n",
      "Validation score: -0.321736\n",
      "Iteration 304, loss = 0.01289268\n",
      "Validation score: -0.320181\n",
      "Iteration 305, loss = 0.01208453\n",
      "Validation score: -0.342347\n",
      "Iteration 306, loss = 0.01258982\n",
      "Validation score: -0.353378\n",
      "Iteration 307, loss = 0.01279207\n",
      "Validation score: -0.356145\n",
      "Iteration 308, loss = 0.01219430\n",
      "Validation score: -0.345736\n",
      "Iteration 309, loss = 0.01215009\n",
      "Validation score: -0.342512\n",
      "Iteration 310, loss = 0.01191543\n",
      "Validation score: -0.354120\n",
      "Iteration 311, loss = 0.01230368\n",
      "Validation score: -0.332866\n",
      "Iteration 312, loss = 0.01233374\n",
      "Validation score: -0.359699\n",
      "Iteration 313, loss = 0.01345078\n",
      "Validation score: -0.346589\n",
      "Iteration 314, loss = 0.01291961\n",
      "Validation score: -0.513229\n",
      "Iteration 315, loss = 0.01718185\n",
      "Validation score: -0.401053\n",
      "Iteration 316, loss = 0.01270007\n",
      "Validation score: -0.332939\n",
      "Iteration 317, loss = 0.01703858\n",
      "Validation score: -0.332521\n",
      "Iteration 318, loss = 0.01572986\n",
      "Validation score: -0.492915\n",
      "Iteration 319, loss = 0.01611289\n",
      "Validation score: -0.427733\n",
      "Iteration 320, loss = 0.01419841\n",
      "Validation score: -0.339704\n",
      "Iteration 321, loss = 0.01385633\n",
      "Validation score: -0.384173\n",
      "Iteration 322, loss = 0.01554475\n",
      "Validation score: -0.344850\n",
      "Iteration 323, loss = 0.01208458\n",
      "Validation score: -0.353049\n",
      "Iteration 324, loss = 0.01723413\n",
      "Validation score: -0.335453\n",
      "Iteration 325, loss = 0.01436908\n",
      "Validation score: -0.327997\n",
      "Iteration 326, loss = 0.01333698\n",
      "Validation score: -0.340719\n",
      "Iteration 327, loss = 0.01595122\n",
      "Validation score: -0.346888\n",
      "Iteration 328, loss = 0.01762063\n",
      "Validation score: -0.333158\n",
      "Iteration 329, loss = 0.01381898\n",
      "Validation score: -0.326270\n",
      "Iteration 330, loss = 0.01207695\n",
      "Validation score: -0.349496\n",
      "Iteration 331, loss = 0.01380791\n",
      "Validation score: -0.334874\n",
      "Iteration 332, loss = 0.01289000\n",
      "Validation score: -0.320740\n",
      "Iteration 333, loss = 0.01235747\n",
      "Validation score: -0.327726\n",
      "Iteration 334, loss = 0.01237752\n",
      "Validation score: -0.366926\n",
      "Iteration 335, loss = 0.01278916\n",
      "Validation score: -0.335818\n",
      "Iteration 336, loss = 0.01218159\n",
      "Validation score: -0.325497\n",
      "Iteration 337, loss = 0.01305325\n",
      "Validation score: -0.313365\n",
      "Iteration 338, loss = 0.01192175\n",
      "Validation score: -0.334671\n",
      "Iteration 339, loss = 0.01178430\n",
      "Validation score: -0.388171\n",
      "Iteration 340, loss = 0.01280749\n",
      "Validation score: -0.326937\n",
      "Iteration 341, loss = 0.01185625\n",
      "Validation score: -0.355809\n",
      "Iteration 342, loss = 0.01375516\n",
      "Validation score: -0.327173\n",
      "Iteration 343, loss = 0.01194879\n",
      "Validation score: -0.412477\n",
      "Iteration 344, loss = 0.01359985\n",
      "Validation score: -0.321632\n",
      "Iteration 345, loss = 0.01204938\n",
      "Validation score: -0.320607\n",
      "Iteration 346, loss = 0.01184390\n",
      "Validation score: -0.341550\n",
      "Iteration 347, loss = 0.01214815\n",
      "Validation score: -0.336236\n",
      "Iteration 348, loss = 0.01218320\n",
      "Validation score: -0.306828\n",
      "Iteration 349, loss = 0.01199994\n",
      "Validation score: -0.310221\n",
      "Iteration 350, loss = 0.01218687\n",
      "Validation score: -0.331574\n",
      "Iteration 351, loss = 0.01213858\n",
      "Validation score: -0.315956\n",
      "Iteration 352, loss = 0.01163928\n",
      "Validation score: -0.337318\n",
      "Iteration 353, loss = 0.01392690\n",
      "Validation score: -0.330658\n",
      "Iteration 354, loss = 0.01323908\n",
      "Validation score: -0.453516\n",
      "Iteration 355, loss = 0.01414998\n",
      "Validation score: -0.323228\n",
      "Iteration 356, loss = 0.01291859\n",
      "Validation score: -0.312168\n",
      "Iteration 357, loss = 0.01166013\n",
      "Validation score: -0.448680\n",
      "Iteration 358, loss = 0.01470049\n",
      "Validation score: -0.397363\n",
      "Iteration 359, loss = 0.01341860\n",
      "Validation score: -0.309698\n",
      "Iteration 360, loss = 0.01234810\n",
      "Validation score: -0.315138\n",
      "Iteration 361, loss = 0.01157692\n",
      "Validation score: -0.379862\n",
      "Iteration 362, loss = 0.01227595\n",
      "Validation score: -0.325200\n",
      "Iteration 363, loss = 0.01153850\n",
      "Validation score: -0.303673\n",
      "Iteration 364, loss = 0.01167956\n",
      "Validation score: -0.317445\n",
      "Iteration 365, loss = 0.01147630\n",
      "Validation score: -0.321544\n",
      "Iteration 366, loss = 0.01141070\n",
      "Validation score: -0.305919\n",
      "Iteration 367, loss = 0.01137737\n",
      "Validation score: -0.303332\n",
      "Iteration 368, loss = 0.01132925\n",
      "Validation score: -0.309875\n",
      "Iteration 369, loss = 0.01131642\n",
      "Validation score: -0.307762\n",
      "Iteration 370, loss = 0.01127394\n",
      "Validation score: -0.305731\n",
      "Iteration 371, loss = 0.01133172\n",
      "Validation score: -0.308216\n",
      "Iteration 372, loss = 0.01135713\n",
      "Validation score: -0.311340\n",
      "Iteration 373, loss = 0.01125949\n",
      "Validation score: -0.313902\n",
      "Iteration 374, loss = 0.01159324\n",
      "Validation score: -0.310453\n",
      "Iteration 375, loss = 0.01149143\n",
      "Validation score: -0.306981\n",
      "Iteration 376, loss = 0.01128170\n",
      "Validation score: -0.308934\n",
      "Iteration 377, loss = 0.01135242\n",
      "Validation score: -0.317893\n",
      "Iteration 378, loss = 0.01134461\n",
      "Validation score: -0.323116\n",
      "Iteration 379, loss = 0.01124923\n",
      "Validation score: -0.314646\n",
      "Iteration 380, loss = 0.01123250\n",
      "Validation score: -0.307759\n",
      "Iteration 381, loss = 0.01122346\n",
      "Validation score: -0.306026\n",
      "Iteration 382, loss = 0.01115690\n",
      "Validation score: -0.302566\n",
      "Iteration 383, loss = 0.01143582\n",
      "Validation score: -0.300458\n",
      "Iteration 384, loss = 0.01138862\n",
      "Validation score: -0.302891\n",
      "Iteration 385, loss = 0.01110993\n",
      "Validation score: -0.311813\n",
      "Iteration 386, loss = 0.01143920\n",
      "Validation score: -0.300140\n",
      "Iteration 387, loss = 0.01119419\n",
      "Validation score: -0.305812\n",
      "Iteration 388, loss = 0.01196965\n",
      "Validation score: -0.333145\n",
      "Iteration 389, loss = 0.01204127\n",
      "Validation score: -0.306548\n",
      "Iteration 390, loss = 0.01114818\n",
      "Validation score: -0.298307\n",
      "Iteration 391, loss = 0.01186594\n",
      "Validation score: -0.299454\n",
      "Iteration 392, loss = 0.01121214\n",
      "Validation score: -0.305738\n",
      "Iteration 393, loss = 0.01448890\n",
      "Validation score: -0.304447\n",
      "Iteration 394, loss = 0.01205957\n",
      "Validation score: -0.302575\n",
      "Iteration 395, loss = 0.01180675\n",
      "Validation score: -0.306599\n",
      "Iteration 396, loss = 0.02002214\n",
      "Validation score: -0.302733\n",
      "Iteration 397, loss = 0.01617857\n",
      "Validation score: -0.310426\n",
      "Iteration 398, loss = 0.01174035\n",
      "Validation score: -0.301738\n",
      "Iteration 399, loss = 0.01516327\n",
      "Validation score: -0.342302\n",
      "Iteration 400, loss = 0.01486860\n",
      "Validation score: -0.361405\n",
      "Iteration 401, loss = 0.01390725\n",
      "Validation score: -0.344327\n",
      "Iteration 402, loss = 0.02715074\n",
      "Validation score: -0.305303\n",
      "Iteration 403, loss = 0.01920667\n",
      "Validation score: -0.306930\n",
      "Iteration 404, loss = 0.01209734\n",
      "Validation score: -0.328368\n",
      "Iteration 405, loss = 0.01879178\n",
      "Validation score: -0.329474\n",
      "Iteration 406, loss = 0.01603391\n",
      "Validation score: -0.300710\n",
      "Iteration 407, loss = 0.01203083\n",
      "Validation score: -0.307820\n",
      "Iteration 408, loss = 0.03604167\n",
      "Validation score: -0.341865\n",
      "Iteration 409, loss = 0.03359553\n",
      "Validation score: -0.310665\n",
      "Iteration 410, loss = 0.01229024\n",
      "Validation score: -0.308627\n",
      "Iteration 411, loss = 0.01875226\n",
      "Validation score: -0.316086\n",
      "Iteration 412, loss = 0.02460708\n",
      "Validation score: -0.319656\n",
      "Iteration 413, loss = 0.01420367\n",
      "Validation score: -0.344305\n",
      "Iteration 414, loss = 0.01333786\n",
      "Validation score: -0.289673\n",
      "Iteration 415, loss = 0.01843367\n",
      "Validation score: -0.287957\n",
      "Iteration 416, loss = 0.01477897\n",
      "Validation score: -0.320802\n",
      "Iteration 417, loss = 0.01124082\n",
      "Validation score: -0.326476\n",
      "Iteration 418, loss = 0.01386274\n",
      "Validation score: -0.304235\n",
      "Iteration 419, loss = 0.01392303\n",
      "Validation score: -0.292663\n",
      "Iteration 420, loss = 0.01122854\n",
      "Validation score: -0.307964\n",
      "Iteration 421, loss = 0.02933557\n",
      "Validation score: -0.296441\n",
      "Iteration 422, loss = 0.01137575\n",
      "Validation score: -0.306902\n",
      "Iteration 423, loss = 0.05106181\n",
      "Validation score: -0.330372\n",
      "Iteration 424, loss = 0.05623086\n",
      "Validation score: -0.314898\n",
      "Iteration 425, loss = 0.01238735\n",
      "Validation score: -0.349976\n",
      "Iteration 426, loss = 0.12153816\n",
      "Validation score: -0.335909\n",
      "Iteration 427, loss = 0.17662150\n",
      "Validation score: -0.309270\n",
      "Iteration 428, loss = 0.04695166\n",
      "Validation score: -0.325380\n",
      "Iteration 429, loss = 0.01271080\n",
      "Validation score: -0.399526\n",
      "Iteration 430, loss = 0.13386065\n",
      "Validation score: -0.407440\n",
      "Iteration 431, loss = 0.18075130\n",
      "Validation score: -0.322281\n",
      "Iteration 432, loss = 0.06862576\n",
      "Validation score: -0.303032\n",
      "Iteration 433, loss = 0.01568971\n",
      "Validation score: -0.326630\n",
      "Iteration 434, loss = 0.04976341\n",
      "Validation score: -0.430716\n",
      "Iteration 435, loss = 0.08789857\n",
      "Validation score: -0.395221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 436, loss = 0.05828946\n",
      "Validation score: -0.301750\n",
      "Iteration 437, loss = 0.01826610\n",
      "Validation score: -0.303797\n",
      "Iteration 438, loss = 0.03440598\n",
      "Validation score: -0.310300\n",
      "Iteration 439, loss = 0.01959799\n",
      "Validation score: -0.377057\n",
      "Iteration 440, loss = 0.01601094\n",
      "Validation score: -0.326408\n",
      "Iteration 441, loss = 0.03869669\n",
      "Validation score: -0.332932\n",
      "Iteration 442, loss = 0.02163413\n",
      "Validation score: -0.334142\n",
      "Iteration 443, loss = 0.02935063\n",
      "Validation score: -0.361188\n",
      "Iteration 444, loss = 0.02601879\n",
      "Validation score: -0.400861\n",
      "Iteration 445, loss = 0.01673718\n",
      "Validation score: -0.324178\n",
      "Iteration 446, loss = 0.01589393\n",
      "Validation score: -0.299874\n",
      "Iteration 447, loss = 0.02126342\n",
      "Validation score: -0.313717\n",
      "Iteration 448, loss = 0.02027442\n",
      "Validation score: -0.315721\n",
      "Iteration 449, loss = 0.01510532\n",
      "Validation score: -0.309057\n",
      "Iteration 450, loss = 0.01203138\n",
      "Validation score: -0.321925\n",
      "Iteration 451, loss = 0.01188255\n",
      "Validation score: -0.335575\n",
      "Iteration 452, loss = 0.01417509\n",
      "Validation score: -0.301583\n",
      "Iteration 453, loss = 0.01429997\n",
      "Validation score: -0.301040\n",
      "Iteration 454, loss = 0.01129032\n",
      "Validation score: -0.325954\n",
      "Iteration 455, loss = 0.01721819\n",
      "Validation score: -0.308375\n",
      "Iteration 456, loss = 0.02154946\n",
      "Validation score: -0.296330\n",
      "Iteration 457, loss = 0.01637759\n",
      "Validation score: -0.305385\n",
      "Iteration 458, loss = 0.01246996\n",
      "Validation score: -0.301038\n",
      "Iteration 459, loss = 0.01139910\n",
      "Validation score: -0.294644\n",
      "Iteration 460, loss = 0.01277873\n",
      "Validation score: -0.284491\n",
      "Iteration 461, loss = 0.01502101\n",
      "Validation score: -0.277493\n",
      "Iteration 462, loss = 0.01214841\n",
      "Validation score: -0.295327\n",
      "Iteration 463, loss = 0.01252176\n",
      "Validation score: -0.302545\n",
      "Iteration 464, loss = 0.01391415\n",
      "Validation score: -0.283056\n",
      "Iteration 465, loss = 0.01450265\n",
      "Validation score: -0.278694\n",
      "Iteration 466, loss = 0.01132560\n",
      "Validation score: -0.289954\n",
      "Iteration 467, loss = 0.01369007\n",
      "Validation score: -0.290670\n",
      "Iteration 468, loss = 0.01834361\n",
      "Validation score: -0.297058\n",
      "Iteration 469, loss = 0.01684509\n",
      "Validation score: -0.295559\n",
      "Iteration 470, loss = 0.01273902\n",
      "Validation score: -0.304725\n",
      "Iteration 471, loss = 0.01172451\n",
      "Validation score: -0.304042\n",
      "Iteration 472, loss = 0.01312502\n",
      "Validation score: -0.295671\n",
      "Iteration 473, loss = 0.01320200\n",
      "Validation score: -0.299101\n",
      "Iteration 474, loss = 0.01236483\n",
      "Validation score: -0.296804\n",
      "Iteration 475, loss = 0.01146215\n",
      "Validation score: -0.294504\n",
      "Iteration 476, loss = 0.01134032\n",
      "Validation score: -0.307391\n",
      "Iteration 477, loss = 0.01170310\n",
      "Validation score: -0.312479\n",
      "Iteration 478, loss = 0.01173939\n",
      "Validation score: -0.306383\n",
      "Iteration 479, loss = 0.01132398\n",
      "Validation score: -0.300881\n",
      "Iteration 480, loss = 0.01091237\n",
      "Validation score: -0.294412\n",
      "Iteration 481, loss = 0.01121349\n",
      "Validation score: -0.291263\n",
      "Iteration 482, loss = 0.01095562\n",
      "Validation score: -0.291899\n",
      "Iteration 483, loss = 0.01092005\n",
      "Validation score: -0.302942\n",
      "Iteration 484, loss = 0.01130167\n",
      "Validation score: -0.299043\n",
      "Iteration 485, loss = 0.01113355\n",
      "Validation score: -0.291942\n",
      "Iteration 486, loss = 0.01086705\n",
      "Validation score: -0.296726\n",
      "Iteration 487, loss = 0.01075778\n",
      "Validation score: -0.309517\n",
      "Iteration 488, loss = 0.01104054\n",
      "Validation score: -0.298201\n",
      "Iteration 489, loss = 0.01094864\n",
      "Validation score: -0.298654\n",
      "Iteration 490, loss = 0.01089778\n",
      "Validation score: -0.312600\n",
      "Iteration 491, loss = 0.01068086\n",
      "Validation score: -0.338968\n",
      "Iteration 492, loss = 0.01104488\n",
      "Validation score: -0.299134\n",
      "Iteration 493, loss = 0.01079645\n",
      "Validation score: -0.325465\n",
      "Iteration 494, loss = 0.01290223\n",
      "Validation score: -0.298758\n",
      "Iteration 495, loss = 0.01088274\n",
      "Validation score: -0.302406\n",
      "Iteration 496, loss = 0.01062887\n",
      "Validation score: -0.293835\n",
      "Iteration 497, loss = 0.01072452\n",
      "Validation score: -0.296673\n",
      "Iteration 498, loss = 0.01062913\n",
      "Validation score: -0.305998\n",
      "Iteration 499, loss = 0.01061711\n",
      "Validation score: -0.308827\n",
      "Iteration 500, loss = 0.01060540\n",
      "Validation score: -0.299507\n",
      "Iteration 501, loss = 0.01059105\n",
      "Validation score: -0.290276\n",
      "Iteration 502, loss = 0.01062974\n",
      "Validation score: -0.298196\n",
      "Iteration 503, loss = 0.01058165\n",
      "Validation score: -0.306890\n",
      "Iteration 504, loss = 0.01069260\n",
      "Validation score: -0.290440\n",
      "Iteration 505, loss = 0.01062038\n",
      "Validation score: -0.286169\n",
      "Iteration 506, loss = 0.01067731\n",
      "Validation score: -0.293131\n",
      "Iteration 507, loss = 0.01054495\n",
      "Validation score: -0.304021\n",
      "Iteration 508, loss = 0.01058590\n",
      "Validation score: -0.296989\n",
      "Iteration 509, loss = 0.01052256\n",
      "Validation score: -0.291925\n",
      "Iteration 510, loss = 0.01055282\n",
      "Validation score: -0.295723\n",
      "Iteration 511, loss = 0.01043856\n",
      "Validation score: -0.293149\n",
      "Iteration 512, loss = 0.01053645\n",
      "Validation score: -0.291238\n",
      "Iteration 513, loss = 0.01054357\n",
      "Validation score: -0.287342\n",
      "Iteration 514, loss = 0.01049986\n",
      "Validation score: -0.289460\n",
      "Iteration 515, loss = 0.01052371\n",
      "Validation score: -0.298513\n",
      "Iteration 516, loss = 0.01066396\n",
      "Validation score: -0.288590\n",
      "Iteration 517, loss = 0.01043202\n",
      "Validation score: -0.288723\n",
      "Iteration 518, loss = 0.01052790\n",
      "Validation score: -0.289282\n",
      "Iteration 519, loss = 0.01042503\n",
      "Validation score: -0.294762\n",
      "Iteration 520, loss = 0.01043867\n",
      "Validation score: -0.297410\n",
      "Iteration 521, loss = 0.01039204\n",
      "Validation score: -0.297487\n",
      "Iteration 522, loss = 0.01040388\n",
      "Validation score: -0.289171\n",
      "Iteration 523, loss = 0.01042107\n",
      "Validation score: -0.290594\n",
      "Iteration 524, loss = 0.01046168\n",
      "Validation score: -0.282544\n",
      "Iteration 525, loss = 0.01039551\n",
      "Validation score: -0.284407\n",
      "Iteration 526, loss = 0.01037402\n",
      "Validation score: -0.298396\n",
      "Iteration 527, loss = 0.01037761\n",
      "Validation score: -0.294919\n",
      "Iteration 528, loss = 0.01034732\n",
      "Validation score: -0.299011\n",
      "Iteration 529, loss = 0.01034457\n",
      "Validation score: -0.299048\n",
      "Iteration 530, loss = 0.01032996\n",
      "Validation score: -0.300792\n",
      "Iteration 531, loss = 0.01030701\n",
      "Validation score: -0.290990\n",
      "Iteration 532, loss = 0.01031802\n",
      "Validation score: -0.296171\n",
      "Iteration 533, loss = 0.01031429\n",
      "Validation score: -0.293090\n",
      "Iteration 534, loss = 0.01036839\n",
      "Validation score: -0.283665\n",
      "Iteration 535, loss = 0.01035145\n",
      "Validation score: -0.280936\n",
      "Iteration 536, loss = 0.01030281\n",
      "Validation score: -0.287075\n",
      "Iteration 537, loss = 0.01039203\n",
      "Validation score: -0.285289\n",
      "Iteration 538, loss = 0.01033171\n",
      "Validation score: -0.285019\n",
      "Iteration 539, loss = 0.01038020\n",
      "Validation score: -0.290346\n",
      "Iteration 540, loss = 0.01045579\n",
      "Validation score: -0.292315\n",
      "Iteration 541, loss = 0.01040544\n",
      "Validation score: -0.299568\n",
      "Iteration 542, loss = 0.01055370\n",
      "Validation score: -0.303808\n",
      "Iteration 543, loss = 0.01041386\n",
      "Validation score: -0.295657\n",
      "Iteration 544, loss = 0.01048463\n",
      "Validation score: -0.284484\n",
      "Iteration 545, loss = 0.01031802\n",
      "Validation score: -0.297161\n",
      "Iteration 546, loss = 0.01079938\n",
      "Validation score: -0.304337\n",
      "Iteration 547, loss = 0.01043729\n",
      "Validation score: -0.363116\n",
      "Iteration 548, loss = 0.01184993\n",
      "Validation score: -0.277381\n",
      "Iteration 549, loss = 0.01039233\n",
      "Validation score: -0.307293\n",
      "Iteration 550, loss = 0.01155702\n",
      "Validation score: -0.303790\n",
      "Iteration 551, loss = 0.01077653\n",
      "Validation score: -0.469579\n",
      "Iteration 552, loss = 0.01416844\n",
      "Validation score: -0.286979\n",
      "Iteration 553, loss = 0.01108885\n",
      "Validation score: -0.644829\n",
      "Iteration 554, loss = 0.02193379\n",
      "Validation score: -0.409031\n",
      "Iteration 555, loss = 0.03913991\n",
      "Validation score: -0.498591\n",
      "Iteration 556, loss = 0.06215038\n",
      "Validation score: -0.863743\n",
      "Iteration 557, loss = 0.03037918\n",
      "Validation score: -3.154376\n",
      "Iteration 558, loss = 0.12888360\n",
      "Validation score: -0.413979\n",
      "Iteration 559, loss = 0.01410474\n",
      "Validation score: -9.526777\n",
      "Iteration 560, loss = 0.31119590\n",
      "Validation score: -6.081708\n",
      "Iteration 561, loss = 0.19684977\n",
      "Validation score: -1.319151\n",
      "Iteration 562, loss = 0.04201476\n",
      "Validation score: -6.321388\n",
      "Iteration 563, loss = 0.18694453\n",
      "Validation score: -3.581669\n",
      "Iteration 564, loss = 0.10851106\n",
      "Validation score: -0.890133\n",
      "Iteration 565, loss = 0.03279578\n",
      "Validation score: -2.926696\n",
      "Iteration 566, loss = 0.08605749\n",
      "Validation score: -2.459340\n",
      "Iteration 567, loss = 0.06382982\n",
      "Validation score: -0.904439\n",
      "Iteration 568, loss = 0.02531312\n",
      "Validation score: -1.423206\n",
      "Iteration 569, loss = 0.04226180\n",
      "Validation score: -1.702422\n",
      "Iteration 570, loss = 0.04453881\n",
      "Validation score: -0.496245\n",
      "Iteration 571, loss = 0.02095125\n",
      "Validation score: -0.966600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 572, loss = 0.03222566\n",
      "Validation score: -0.929667\n",
      "Iteration 573, loss = 0.03315910\n",
      "Validation score: -0.582674\n",
      "Iteration 574, loss = 0.02416041\n",
      "Validation score: -0.670055\n",
      "Iteration 575, loss = 0.02221651\n",
      "Validation score: -0.749687\n",
      "Iteration 576, loss = 0.02138226\n",
      "Validation score: -0.543531\n",
      "Iteration 577, loss = 0.01773816\n",
      "Validation score: -0.415075\n",
      "Iteration 578, loss = 0.01469380\n",
      "Validation score: -0.341837\n",
      "Iteration 579, loss = 0.01996426\n",
      "Validation score: -0.400751\n",
      "Iteration 580, loss = 0.02228137\n",
      "Validation score: -0.460111\n",
      "Iteration 581, loss = 0.01672066\n",
      "Validation score: -0.326795\n",
      "Iteration 582, loss = 0.01197657\n",
      "Validation score: -0.346146\n",
      "Iteration 583, loss = 0.01722023\n",
      "Validation score: -0.337247\n",
      "Iteration 584, loss = 0.01482767\n",
      "Validation score: -0.365071\n",
      "Iteration 585, loss = 0.01213889\n",
      "Validation score: -0.424366\n",
      "Iteration 586, loss = 0.01489918\n",
      "Validation score: -0.352299\n",
      "Iteration 587, loss = 0.01320538\n",
      "Validation score: -0.295327\n",
      "Iteration 588, loss = 0.01112853\n",
      "Validation score: -0.293812\n",
      "Iteration 589, loss = 0.01112942\n",
      "Validation score: -0.309791\n",
      "Iteration 590, loss = 0.01235418\n",
      "Validation score: -0.288312\n",
      "Iteration 591, loss = 0.01141673\n",
      "Validation score: -0.283307\n",
      "Iteration 592, loss = 0.01069768\n",
      "Validation score: -0.300438\n",
      "Iteration 593, loss = 0.01163488\n",
      "Validation score: -0.297667\n",
      "Iteration 594, loss = 0.01085711\n",
      "Validation score: -0.292991\n",
      "Iteration 595, loss = 0.01069903\n",
      "Validation score: -0.293601\n",
      "Iteration 596, loss = 0.01132865\n",
      "Validation score: -0.285068\n",
      "Iteration 597, loss = 0.01071028\n",
      "Validation score: -0.286025\n",
      "Iteration 598, loss = 0.01032978\n",
      "Validation score: -0.287037\n",
      "Iteration 599, loss = 0.01036187\n",
      "Validation score: -0.279024\n",
      "Iteration 600, loss = 0.01024659\n",
      "Validation score: -0.282218\n",
      "Iteration 601, loss = 0.01013833\n",
      "Validation score: -0.287875\n",
      "Iteration 602, loss = 0.01026391\n",
      "Validation score: -0.280273\n",
      "Iteration 603, loss = 0.01037748\n",
      "Validation score: -0.277751\n",
      "Iteration 604, loss = 0.01032412\n",
      "Validation score: -0.280156\n",
      "Iteration 605, loss = 0.01007262\n",
      "Validation score: -0.288910\n",
      "Iteration 606, loss = 0.01008098\n",
      "Validation score: -0.301908\n",
      "Iteration 607, loss = 0.01036056\n",
      "Validation score: -0.290410\n",
      "Iteration 608, loss = 0.01022573\n",
      "Validation score: -0.282414\n",
      "Iteration 609, loss = 0.01008235\n",
      "Validation score: -0.285107\n",
      "Iteration 610, loss = 0.01009765\n",
      "Validation score: -0.285102\n",
      "Iteration 611, loss = 0.01011002\n",
      "Validation score: -0.286781\n",
      "Iteration 612, loss = 0.01013146\n",
      "Validation score: -0.287888\n",
      "Iteration 613, loss = 0.01006945\n",
      "Validation score: -0.284099\n",
      "Iteration 614, loss = 0.01002972\n",
      "Validation score: -0.279817\n",
      "Iteration 615, loss = 0.00997083\n",
      "Validation score: -0.275711\n",
      "Iteration 616, loss = 0.01001284\n",
      "Validation score: -0.276328\n",
      "Iteration 617, loss = 0.01008482\n",
      "Validation score: -0.279350\n",
      "Iteration 618, loss = 0.00997018\n",
      "Validation score: -0.282460\n",
      "Iteration 619, loss = 0.01014046\n",
      "Validation score: -0.283713\n",
      "Iteration 620, loss = 0.01025658\n",
      "Validation score: -0.283215\n",
      "Iteration 621, loss = 0.01008606\n",
      "Validation score: -0.281849\n",
      "Iteration 622, loss = 0.01002680\n",
      "Validation score: -0.279705\n",
      "Iteration 623, loss = 0.00994685\n",
      "Validation score: -0.271427\n",
      "Iteration 624, loss = 0.01001663\n",
      "Validation score: -0.266732\n",
      "Iteration 625, loss = 0.01011903\n",
      "Validation score: -0.269144\n",
      "Iteration 626, loss = 0.00997568\n",
      "Validation score: -0.273985\n",
      "Iteration 627, loss = 0.00992341\n",
      "Validation score: -0.283202\n",
      "Iteration 628, loss = 0.01002479\n",
      "Validation score: -0.286213\n",
      "Iteration 629, loss = 0.00993381\n",
      "Validation score: -0.287657\n",
      "Iteration 630, loss = 0.01000883\n",
      "Validation score: -0.286211\n",
      "Iteration 631, loss = 0.01003125\n",
      "Validation score: -0.283552\n",
      "Iteration 632, loss = 0.00994415\n",
      "Validation score: -0.281952\n",
      "Iteration 633, loss = 0.00994422\n",
      "Validation score: -0.279122\n",
      "Iteration 634, loss = 0.00992165\n",
      "Validation score: -0.279433\n",
      "Iteration 635, loss = 0.00988606\n",
      "Validation score: -0.283000\n",
      "Iteration 636, loss = 0.00989807\n",
      "Validation score: -0.285409\n",
      "Iteration 637, loss = 0.00986884\n",
      "Validation score: -0.281858\n",
      "Iteration 638, loss = 0.00986494\n",
      "Validation score: -0.270914\n",
      "Iteration 639, loss = 0.00988181\n",
      "Validation score: -0.265273\n",
      "Iteration 640, loss = 0.00998871\n",
      "Validation score: -0.270306\n",
      "Iteration 641, loss = 0.00997069\n",
      "Validation score: -0.281436\n",
      "Iteration 642, loss = 0.00997454\n",
      "Validation score: -0.281580\n",
      "Iteration 643, loss = 0.00990204\n",
      "Validation score: -0.278736\n",
      "Iteration 644, loss = 0.00980466\n",
      "Validation score: -0.285342\n",
      "Iteration 645, loss = 0.01021621\n",
      "Validation score: -0.279233\n",
      "Iteration 646, loss = 0.00988498\n",
      "Validation score: -0.282642\n",
      "Iteration 647, loss = 0.00982458\n",
      "Validation score: -0.287860\n",
      "Iteration 648, loss = 0.00992821\n",
      "Validation score: -0.286539\n",
      "Iteration 649, loss = 0.01000466\n",
      "Validation score: -0.277705\n",
      "Iteration 650, loss = 0.00985041\n",
      "Validation score: -0.273822\n",
      "Iteration 651, loss = 0.00978120\n",
      "Validation score: -0.274451\n",
      "Iteration 652, loss = 0.00987859\n",
      "Validation score: -0.279053\n",
      "Iteration 653, loss = 0.01011742\n",
      "Validation score: -0.277091\n",
      "Iteration 654, loss = 0.00978713\n",
      "Validation score: -0.273172\n",
      "Iteration 655, loss = 0.00992132\n",
      "Validation score: -0.275308\n",
      "Iteration 656, loss = 0.00983402\n",
      "Validation score: -0.280712\n",
      "Iteration 657, loss = 0.00987078\n",
      "Validation score: -0.283735\n",
      "Iteration 658, loss = 0.00994014\n",
      "Validation score: -0.281634\n",
      "Iteration 659, loss = 0.00984089\n",
      "Validation score: -0.280057\n",
      "Iteration 660, loss = 0.00978455\n",
      "Validation score: -0.279765\n",
      "Iteration 661, loss = 0.00975636\n",
      "Validation score: -0.280346\n",
      "Iteration 662, loss = 0.00973463\n",
      "Validation score: -0.281491\n",
      "Iteration 663, loss = 0.00975101\n",
      "Validation score: -0.282089\n",
      "Iteration 664, loss = 0.00975289\n",
      "Validation score: -0.282958\n",
      "Iteration 665, loss = 0.00971529\n",
      "Validation score: -0.281652\n",
      "Iteration 666, loss = 0.00967652\n",
      "Validation score: -0.277998\n",
      "Iteration 667, loss = 0.00968383\n",
      "Validation score: -0.274429\n",
      "Iteration 668, loss = 0.00966969\n",
      "Validation score: -0.273123\n",
      "Iteration 669, loss = 0.00968755\n",
      "Validation score: -0.274389\n",
      "Iteration 670, loss = 0.00972028\n",
      "Validation score: -0.279411\n",
      "Iteration 671, loss = 0.00967663\n",
      "Validation score: -0.281132\n",
      "Iteration 672, loss = 0.00990525\n",
      "Validation score: -0.278581\n",
      "Iteration 673, loss = 0.00986654\n",
      "Validation score: -0.277448\n",
      "Iteration 674, loss = 0.00965716\n",
      "Validation score: -0.279809\n",
      "Iteration 675, loss = 0.00968930\n",
      "Validation score: -0.282353\n",
      "Iteration 676, loss = 0.00971382\n",
      "Validation score: -0.286641\n",
      "Iteration 677, loss = 0.00965510\n",
      "Validation score: -0.288098\n",
      "Iteration 678, loss = 0.00965816\n",
      "Validation score: -0.282235\n",
      "Iteration 679, loss = 0.00963914\n",
      "Validation score: -0.273866\n",
      "Iteration 680, loss = 0.00961725\n",
      "Validation score: -0.267729\n",
      "Iteration 681, loss = 0.00973768\n",
      "Validation score: -0.267336\n",
      "Iteration 682, loss = 0.00976262\n",
      "Validation score: -0.271687\n",
      "Iteration 683, loss = 0.00976210\n",
      "Validation score: -0.271492\n",
      "Iteration 684, loss = 0.00965055\n",
      "Validation score: -0.268224\n",
      "Iteration 685, loss = 0.00968197\n",
      "Validation score: -0.265620\n",
      "Iteration 686, loss = 0.00974808\n",
      "Validation score: -0.271431\n",
      "Iteration 687, loss = 0.00961838\n",
      "Validation score: -0.281440\n",
      "Iteration 688, loss = 0.00956145\n",
      "Validation score: -0.284342\n",
      "Iteration 689, loss = 0.00966167\n",
      "Validation score: -0.282618\n",
      "Iteration 690, loss = 0.00955616\n",
      "Validation score: -0.280137\n",
      "Iteration 691, loss = 0.00993112\n",
      "Validation score: -0.281110\n",
      "Iteration 692, loss = 0.00951683\n",
      "Validation score: -0.282631\n",
      "Iteration 693, loss = 0.01062557\n",
      "Validation score: -0.276854\n",
      "Iteration 694, loss = 0.01069448\n",
      "Validation score: -0.275358\n",
      "Iteration 695, loss = 0.00960930\n",
      "Validation score: -0.280645\n",
      "Iteration 696, loss = 0.00984259\n",
      "Validation score: -0.287810\n",
      "Iteration 697, loss = 0.01025477\n",
      "Validation score: -0.286654\n",
      "Iteration 698, loss = 0.00956738\n",
      "Validation score: -0.278563\n",
      "Iteration 699, loss = 0.01236072\n",
      "Validation score: -0.272297\n",
      "Iteration 700, loss = 0.01241783\n",
      "Validation score: -0.275701\n",
      "Iteration 701, loss = 0.01000580\n",
      "Validation score: -0.285982\n",
      "Iteration 702, loss = 0.01944149\n",
      "Validation score: -0.284828\n",
      "Iteration 703, loss = 0.01914753\n",
      "Validation score: -0.278716\n",
      "Iteration 704, loss = 0.01068000\n",
      "Validation score: -0.277079\n",
      "Iteration 705, loss = 0.01150113\n",
      "Validation score: -0.273296\n",
      "Iteration 706, loss = 0.01484607\n",
      "Validation score: -0.262644\n",
      "Iteration 707, loss = 0.01103228\n",
      "Validation score: -0.267735\n",
      "Iteration 708, loss = 0.01034571\n",
      "Validation score: -0.275105\n",
      "Iteration 709, loss = 0.01768836\n",
      "Validation score: -0.308791\n",
      "Iteration 710, loss = 0.01672504\n",
      "Validation score: -0.289710\n",
      "Iteration 711, loss = 0.01027677\n",
      "Validation score: -0.282434\n",
      "Iteration 712, loss = 0.01203454\n",
      "Validation score: -0.275038\n",
      "Iteration 713, loss = 0.01430938\n",
      "Validation score: -0.291090\n",
      "Iteration 714, loss = 0.01038508\n",
      "Validation score: -0.289780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 715, loss = 0.02919093\n",
      "Validation score: -0.316436\n",
      "Iteration 716, loss = 0.01581603\n",
      "Validation score: -0.317376\n",
      "Iteration 717, loss = 0.01832248\n",
      "Validation score: -0.272104\n",
      "Iteration 718, loss = 0.01407179\n",
      "Validation score: -0.277360\n",
      "Iteration 719, loss = 0.01161624\n",
      "Validation score: -0.312147\n",
      "Iteration 720, loss = 0.01332398\n",
      "Validation score: -0.313524\n",
      "Iteration 721, loss = 0.01240643\n",
      "Validation score: -0.298949\n",
      "Iteration 722, loss = 0.01036964\n",
      "Validation score: -0.294050\n",
      "Iteration 723, loss = 0.01117586\n",
      "Validation score: -0.299387\n",
      "Iteration 724, loss = 0.01114672\n",
      "Validation score: -0.287416\n",
      "Iteration 725, loss = 0.01020246\n",
      "Validation score: -0.294242\n",
      "Iteration 726, loss = 0.01054318\n",
      "Validation score: -0.273752\n",
      "Iteration 727, loss = 0.01041972\n",
      "Validation score: -0.273902\n",
      "Iteration 728, loss = 0.01008063\n",
      "Validation score: -0.323359\n",
      "Iteration 729, loss = 0.01069006\n",
      "Validation score: -0.270515\n",
      "Iteration 730, loss = 0.01154212\n",
      "Validation score: -0.286860\n",
      "Iteration 731, loss = 0.00979178\n",
      "Validation score: -0.628617\n",
      "Iteration 732, loss = 0.01440917\n",
      "Validation score: -0.467470\n",
      "Iteration 733, loss = 0.01236930\n",
      "Validation score: -0.293754\n",
      "Iteration 734, loss = 0.01102441\n",
      "Validation score: -0.409762\n",
      "Iteration 735, loss = 0.01279478\n",
      "Validation score: -0.288171\n",
      "Iteration 736, loss = 0.01283309\n",
      "Validation score: -0.354661\n",
      "Iteration 737, loss = 0.01364231\n",
      "Validation score: -0.373500\n",
      "Iteration 738, loss = 0.01101764\n",
      "Validation score: -0.271639\n",
      "Iteration 739, loss = 0.01030038\n",
      "Validation score: -0.283319\n",
      "Iteration 740, loss = 0.01233123\n",
      "Validation score: -0.277699\n",
      "Iteration 741, loss = 0.00961641\n",
      "Validation score: -0.306140\n",
      "Iteration 742, loss = 0.01599447\n",
      "Validation score: -0.323033\n",
      "Iteration 743, loss = 0.01691084\n",
      "Validation score: -0.280014\n",
      "Iteration 744, loss = 0.00987268\n",
      "Validation score: -0.277036\n",
      "Iteration 745, loss = 0.01137302\n",
      "Validation score: -0.276915\n",
      "Iteration 746, loss = 0.01364989\n",
      "Validation score: -0.285195\n",
      "Iteration 747, loss = 0.01041233\n",
      "Validation score: -0.292633\n",
      "Iteration 748, loss = 0.00963504\n",
      "Validation score: -0.290041\n",
      "Iteration 749, loss = 0.01521528\n",
      "Validation score: -0.285766\n",
      "Iteration 750, loss = 0.01570314\n",
      "Validation score: -0.306036\n",
      "Iteration 751, loss = 0.01043918\n",
      "Validation score: -0.281406\n",
      "Iteration 752, loss = 0.01013911\n",
      "Validation score: -0.270977\n",
      "Iteration 753, loss = 0.01389387\n",
      "Validation score: -0.288065\n",
      "Iteration 754, loss = 0.01112140\n",
      "Validation score: -0.334108\n",
      "Iteration 755, loss = 0.01243304\n",
      "Validation score: -0.274246\n",
      "Iteration 756, loss = 0.01057009\n",
      "Validation score: -0.399521\n",
      "Iteration 757, loss = 0.01347774\n",
      "Validation score: -0.317625\n",
      "Iteration 758, loss = 0.01093609\n",
      "Validation score: -1.056489\n",
      "Iteration 759, loss = 0.02272234\n",
      "Validation score: -0.570414\n",
      "Iteration 760, loss = 0.01255252\n",
      "Validation score: -0.311241\n",
      "Iteration 761, loss = 0.01084067\n",
      "Validation score: -0.754495\n",
      "Iteration 762, loss = 0.02017841\n",
      "Validation score: -0.341769\n",
      "Iteration 763, loss = 0.01205031\n",
      "Validation score: -0.507295\n",
      "Iteration 764, loss = 0.01300574\n",
      "Validation score: -0.609677\n",
      "Iteration 765, loss = 0.01344540\n",
      "Validation score: -0.320707\n",
      "Iteration 766, loss = 0.00987199\n",
      "Validation score: -0.445787\n",
      "Iteration 767, loss = 0.01269651\n",
      "Validation score: -0.358219\n",
      "Iteration 768, loss = 0.01145976\n",
      "Validation score: -0.311730\n",
      "Iteration 769, loss = 0.00995599\n",
      "Validation score: -0.365333\n",
      "Iteration 770, loss = 0.00985879\n",
      "Validation score: -0.277346\n",
      "Iteration 771, loss = 0.00956461\n",
      "Validation score: -0.351991\n",
      "Iteration 772, loss = 0.01168708\n",
      "Validation score: -0.298480\n",
      "Iteration 773, loss = 0.00955623\n",
      "Validation score: -0.389704\n",
      "Iteration 774, loss = 0.01151869\n",
      "Validation score: -0.388436\n",
      "Iteration 775, loss = 0.01025399\n",
      "Validation score: -0.289926\n",
      "Iteration 776, loss = 0.00982862\n",
      "Validation score: -0.290867\n",
      "Iteration 777, loss = 0.00978900\n",
      "Validation score: -0.316538\n",
      "Iteration 778, loss = 0.00982845\n",
      "Validation score: -0.339485\n",
      "Iteration 779, loss = 0.00984487\n",
      "Validation score: -0.291131\n",
      "Iteration 780, loss = 0.00932988\n",
      "Validation score: -0.284438\n",
      "Iteration 781, loss = 0.00958080\n",
      "Validation score: -0.291526\n",
      "Iteration 782, loss = 0.00953391\n",
      "Validation score: -0.317191\n",
      "Iteration 783, loss = 0.00928468\n",
      "Validation score: -0.285089\n",
      "Iteration 784, loss = 0.00920509\n",
      "Validation score: -0.291597\n",
      "Iteration 785, loss = 0.00985583\n",
      "Validation score: -0.281602\n",
      "Iteration 786, loss = 0.00914988\n",
      "Validation score: -0.304669\n",
      "Iteration 787, loss = 0.01173920\n",
      "Validation score: -0.295034\n",
      "Iteration 788, loss = 0.00909806\n",
      "Validation score: -0.299085\n",
      "Iteration 789, loss = 0.01888608\n",
      "Validation score: -0.292629\n",
      "Iteration 790, loss = 0.01762828\n",
      "Validation score: -0.310604\n",
      "Iteration 791, loss = 0.00961372\n",
      "Validation score: -0.335362\n",
      "Iteration 792, loss = 0.01411092\n",
      "Validation score: -0.289287\n",
      "Iteration 793, loss = 0.01590948\n",
      "Validation score: -0.285468\n",
      "Iteration 794, loss = 0.01009778\n",
      "Validation score: -0.304547\n",
      "Iteration 795, loss = 0.01087790\n",
      "Validation score: -0.311333\n",
      "Iteration 796, loss = 0.01218382\n",
      "Validation score: -0.291013\n",
      "Iteration 797, loss = 0.00993352\n",
      "Validation score: -0.293484\n",
      "Iteration 798, loss = 0.02752837\n",
      "Validation score: -0.298453\n",
      "Iteration 799, loss = 0.01601279\n",
      "Validation score: -0.314931\n",
      "Iteration 800, loss = 0.01112591\n",
      "Validation score: -0.329800\n",
      "Iteration 801, loss = 0.05640513\n",
      "Validation score: -0.321731\n",
      "Iteration 802, loss = 0.04624359\n",
      "Validation score: -0.329578\n",
      "Iteration 803, loss = 0.01141678\n",
      "Validation score: -0.298465\n",
      "Iteration 804, loss = 0.01211690\n",
      "Validation score: -0.383479\n",
      "Iteration 805, loss = 0.01410933\n",
      "Validation score: -0.391714\n",
      "Iteration 806, loss = 0.01174914\n",
      "Validation score: -0.312141\n",
      "Iteration 807, loss = 0.01826397\n",
      "Validation score: -0.332912\n",
      "Iteration 808, loss = 0.02008364\n",
      "Validation score: -0.367906\n",
      "Iteration 809, loss = 0.01176384\n",
      "Validation score: -0.307260\n",
      "Iteration 810, loss = 0.00994619\n",
      "Validation score: -0.317491\n",
      "Iteration 811, loss = 0.01495510\n",
      "Validation score: -0.370050\n",
      "Iteration 812, loss = 0.01567491\n",
      "Validation score: -0.297980\n",
      "Iteration 813, loss = 0.00985992\n",
      "Validation score: -0.558187\n",
      "Iteration 814, loss = 0.01816400\n",
      "Validation score: -0.539688\n",
      "Iteration 815, loss = 0.01444447\n",
      "Validation score: -0.314534\n",
      "Iteration 816, loss = 0.01346530\n",
      "Validation score: -0.493315\n",
      "Iteration 817, loss = 0.01888246\n",
      "Validation score: -0.485493\n",
      "Iteration 818, loss = 0.01384214\n",
      "Validation score: -0.305937\n",
      "Iteration 819, loss = 0.01026655\n",
      "Validation score: -0.358562\n",
      "Iteration 820, loss = 0.01256122\n",
      "Validation score: -0.424748\n",
      "Iteration 821, loss = 0.01207486\n",
      "Validation score: -0.327288\n",
      "Iteration 822, loss = 0.00972716\n",
      "Validation score: -0.332309\n",
      "Iteration 823, loss = 0.00989069\n",
      "Validation score: -0.347326\n",
      "Iteration 824, loss = 0.00987045\n",
      "Validation score: -0.319112\n",
      "Iteration 825, loss = 0.00960734\n",
      "Validation score: -0.380912\n",
      "Iteration 826, loss = 0.01009229\n",
      "Validation score: -0.361507\n",
      "Iteration 827, loss = 0.00961179\n",
      "Validation score: -0.301525\n",
      "Iteration 828, loss = 0.00911875\n",
      "Validation score: -0.411517\n",
      "Iteration 829, loss = 0.01085432\n",
      "Validation score: -0.356126\n",
      "Iteration 830, loss = 0.00946615\n",
      "Validation score: -0.374692\n",
      "Iteration 831, loss = 0.00993034\n",
      "Validation score: -0.436177\n",
      "Iteration 832, loss = 0.01099486\n",
      "Validation score: -0.322992\n",
      "Iteration 833, loss = 0.00934402\n",
      "Validation score: -0.321816\n",
      "Iteration 834, loss = 0.00951320\n",
      "Validation score: -0.390957\n",
      "Iteration 835, loss = 0.01012753\n",
      "Validation score: -0.316676\n",
      "Iteration 836, loss = 0.00908323\n",
      "Validation score: -0.306720\n",
      "Iteration 837, loss = 0.00959352\n",
      "Validation score: -0.315377\n",
      "Iteration 838, loss = 0.00939634\n",
      "Validation score: -0.341749\n",
      "Iteration 839, loss = 0.00917539\n",
      "Validation score: -0.313328\n",
      "Iteration 840, loss = 0.00883956\n",
      "Validation score: -0.357987\n",
      "Iteration 841, loss = 0.01003955\n",
      "Validation score: -0.304746\n",
      "Iteration 842, loss = 0.00888089\n",
      "Validation score: -0.528061\n",
      "Iteration 843, loss = 0.01143854\n",
      "Validation score: -0.347294\n",
      "Iteration 844, loss = 0.00927252\n",
      "Validation score: -0.355705\n",
      "Iteration 845, loss = 0.00987266\n",
      "Validation score: -0.332561\n",
      "Iteration 846, loss = 0.00938218\n",
      "Validation score: -0.422929\n",
      "Iteration 847, loss = 0.00990496\n",
      "Validation score: -0.306048\n",
      "Iteration 848, loss = 0.00949846\n",
      "Validation score: -0.307515\n",
      "Iteration 849, loss = 0.00881326\n",
      "Validation score: -0.486401\n",
      "Iteration 850, loss = 0.01171393\n",
      "Validation score: -0.400316\n",
      "Iteration 851, loss = 0.00968366\n",
      "Validation score: -0.322699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 852, loss = 0.00905815\n",
      "Validation score: -0.348811\n",
      "Iteration 853, loss = 0.01096350\n",
      "Validation score: -0.350483\n",
      "Iteration 854, loss = 0.00975219\n",
      "Validation score: -0.326181\n",
      "Iteration 855, loss = 0.00904504\n",
      "Validation score: -0.365503\n",
      "Iteration 856, loss = 0.00966331\n",
      "Validation score: -0.368756\n",
      "Iteration 857, loss = 0.00947945\n",
      "Validation score: -0.312813\n",
      "Iteration 858, loss = 0.00885254\n",
      "Validation score: -0.338169\n",
      "Iteration 859, loss = 0.00902282\n",
      "Validation score: -0.315585\n",
      "Iteration 860, loss = 0.00870169\n",
      "Validation score: -0.335530\n",
      "Iteration 861, loss = 0.00917000\n",
      "Validation score: -0.353329\n",
      "Iteration 862, loss = 0.00916670\n",
      "Validation score: -0.328509\n",
      "Iteration 863, loss = 0.00868737\n",
      "Validation score: -0.383356\n",
      "Iteration 864, loss = 0.00927584\n",
      "Validation score: -0.360911\n",
      "Iteration 865, loss = 0.00921593\n",
      "Validation score: -0.307645\n",
      "Iteration 866, loss = 0.00883883\n",
      "Validation score: -0.317983\n",
      "Iteration 867, loss = 0.00882472\n",
      "Validation score: -0.336680\n",
      "Iteration 868, loss = 0.00897428\n",
      "Validation score: -0.312172\n",
      "Iteration 869, loss = 0.00884895\n",
      "Validation score: -0.325003\n",
      "Iteration 870, loss = 0.00909866\n",
      "Validation score: -0.320883\n",
      "Iteration 871, loss = 0.00867191\n",
      "Validation score: -0.371827\n",
      "Iteration 872, loss = 0.00925500\n",
      "Validation score: -0.373498\n",
      "Iteration 873, loss = 0.00925320\n",
      "Validation score: -0.321255\n",
      "Iteration 874, loss = 0.00877299\n",
      "Validation score: -0.315222\n",
      "Iteration 875, loss = 0.00888398\n",
      "Validation score: -0.345711\n",
      "Iteration 876, loss = 0.00900012\n",
      "Validation score: -0.339480\n",
      "Iteration 877, loss = 0.00873540\n",
      "Validation score: -0.324846\n",
      "Iteration 878, loss = 0.00862242\n",
      "Validation score: -0.331522\n",
      "Iteration 879, loss = 0.00877942\n",
      "Validation score: -0.323839\n",
      "Iteration 880, loss = 0.00862625\n",
      "Validation score: -0.322710\n",
      "Iteration 881, loss = 0.00854521\n",
      "Validation score: -0.338710\n",
      "Iteration 882, loss = 0.00870445\n",
      "Validation score: -0.327448\n",
      "Iteration 883, loss = 0.00865403\n",
      "Validation score: -0.320174\n",
      "Iteration 884, loss = 0.00855493\n",
      "Validation score: -0.325225\n",
      "Iteration 885, loss = 0.00863318\n",
      "Validation score: -0.324890\n",
      "Iteration 886, loss = 0.00853951\n",
      "Validation score: -0.320005\n",
      "Iteration 887, loss = 0.00884809\n",
      "Validation score: -0.317785\n",
      "Iteration 888, loss = 0.00859817\n",
      "Validation score: -0.322417\n",
      "Iteration 889, loss = 0.00921421\n",
      "Validation score: -0.317498\n",
      "Iteration 890, loss = 0.00913112\n",
      "Validation score: -0.313140\n",
      "Iteration 891, loss = 0.00870801\n",
      "Validation score: -0.323896\n",
      "Iteration 892, loss = 0.00856872\n",
      "Validation score: -0.359318\n",
      "Iteration 893, loss = 0.00910088\n",
      "Validation score: -0.334527\n",
      "Iteration 894, loss = 0.00869238\n",
      "Validation score: -0.329705\n",
      "Iteration 895, loss = 0.00872161\n",
      "Validation score: -0.338823\n",
      "Iteration 896, loss = 0.00980403\n",
      "Validation score: -0.379418\n",
      "Iteration 897, loss = 0.01076850\n",
      "Validation score: -0.335824\n",
      "Iteration 898, loss = 0.00918527\n",
      "Validation score: -0.315732\n",
      "Iteration 899, loss = 0.00982806\n",
      "Validation score: -0.322614\n",
      "Iteration 900, loss = 0.01029675\n",
      "Validation score: -0.324360\n",
      "Iteration 901, loss = 0.00875986\n",
      "Validation score: -0.326915\n",
      "Iteration 902, loss = 0.00975071\n",
      "Validation score: -0.324642\n",
      "Iteration 903, loss = 0.00936431\n",
      "Validation score: -0.350257\n",
      "Iteration 904, loss = 0.00905081\n",
      "Validation score: -0.323214\n",
      "Iteration 905, loss = 0.01259242\n",
      "Validation score: -0.328769\n",
      "Iteration 906, loss = 0.01239238\n",
      "Validation score: -0.420978\n",
      "Iteration 907, loss = 0.01122958\n",
      "Validation score: -0.599276\n",
      "Iteration 908, loss = 0.01569549\n",
      "Validation score: -0.376319\n",
      "Iteration 909, loss = 0.01337097\n",
      "Validation score: -0.753835\n",
      "Iteration 910, loss = 0.02266057\n",
      "Validation score: -0.426453\n",
      "Iteration 911, loss = 0.01291004\n",
      "Validation score: -0.375787\n",
      "Iteration 912, loss = 0.01080294\n",
      "Validation score: -0.560857\n",
      "Iteration 913, loss = 0.01816582\n",
      "Validation score: -0.454147\n",
      "Iteration 914, loss = 0.03448450\n",
      "Validation score: -0.766662\n",
      "Iteration 915, loss = 0.03120290\n",
      "Validation score: -5.471276\n",
      "Iteration 916, loss = 0.17729954\n",
      "Validation score: -0.377354\n",
      "Iteration 917, loss = 0.01023489\n",
      "Validation score: -4.603533\n",
      "Iteration 918, loss = 0.12378286\n",
      "Validation score: -1.349024\n",
      "Iteration 919, loss = 0.03329077\n",
      "Validation score: -1.226996\n",
      "Iteration 920, loss = 0.04163952\n",
      "Validation score: -1.517535\n",
      "Iteration 921, loss = 0.05437408\n",
      "Validation score: -0.552208\n",
      "Iteration 922, loss = 0.01207164\n",
      "Validation score: -1.859304\n",
      "Iteration 923, loss = 0.04088012\n",
      "Validation score: -0.525612\n",
      "Iteration 924, loss = 0.01232891\n",
      "Validation score: -0.349404\n",
      "Iteration 925, loss = 0.01321674\n",
      "Validation score: -0.486793\n",
      "Iteration 926, loss = 0.01322027\n",
      "Validation score: -0.533232\n",
      "Iteration 927, loss = 0.01129360\n",
      "Validation score: -0.377013\n",
      "Iteration 928, loss = 0.00997625\n",
      "Validation score: -0.575247\n",
      "Iteration 929, loss = 0.01490780\n",
      "Validation score: -0.344705\n",
      "Iteration 930, loss = 0.01090107\n",
      "Validation score: -0.627890\n",
      "Iteration 931, loss = 0.01285866\n",
      "Validation score: -0.450667\n",
      "Iteration 932, loss = 0.01380417\n",
      "Validation score: -0.368098\n",
      "Iteration 933, loss = 0.01486870\n",
      "Validation score: -0.521172\n",
      "Iteration 934, loss = 0.01341535\n",
      "Validation score: -0.436525\n",
      "Iteration 935, loss = 0.01466503\n",
      "Validation score: -0.393237\n",
      "Iteration 936, loss = 0.01126685\n",
      "Validation score: -0.531612\n",
      "Iteration 937, loss = 0.01244574\n",
      "Validation score: -0.391901\n",
      "Iteration 938, loss = 0.01090456\n",
      "Validation score: -0.335015\n",
      "Iteration 939, loss = 0.00921487\n",
      "Validation score: -0.559677\n",
      "Iteration 940, loss = 0.01216180\n",
      "Validation score: -0.529586\n",
      "Iteration 941, loss = 0.01114953\n",
      "Validation score: -0.354321\n",
      "Iteration 942, loss = 0.00900161\n",
      "Validation score: -0.433510\n",
      "Iteration 943, loss = 0.01152779\n",
      "Validation score: -0.336207\n",
      "Iteration 944, loss = 0.00903515\n",
      "Validation score: -0.530213\n",
      "Iteration 945, loss = 0.01127812\n",
      "Validation score: -0.509761\n",
      "Iteration 946, loss = 0.01108109\n",
      "Validation score: -0.336835\n",
      "Iteration 947, loss = 0.00870974\n",
      "Validation score: -0.448334\n",
      "Iteration 948, loss = 0.01100313\n",
      "Validation score: -0.386023\n",
      "Iteration 949, loss = 0.00972400\n",
      "Validation score: -0.390750\n",
      "Iteration 950, loss = 0.00893639\n",
      "Validation score: -0.429259\n",
      "Iteration 951, loss = 0.01004625\n",
      "Validation score: -0.338330\n",
      "Iteration 952, loss = 0.00905493\n",
      "Validation score: -0.351044\n",
      "Iteration 953, loss = 0.00883659\n",
      "Validation score: -0.530581\n",
      "Iteration 954, loss = 0.01262970\n",
      "Validation score: -0.343433\n",
      "Iteration 955, loss = 0.00855008\n",
      "Validation score: -0.584874\n",
      "Iteration 956, loss = 0.01864907\n",
      "Validation score: -0.383908\n",
      "Iteration 957, loss = 0.01095831\n",
      "Validation score: -0.681290\n",
      "Iteration 958, loss = 0.01509665\n",
      "Validation score: -0.366820\n",
      "Iteration 959, loss = 0.00967742\n",
      "Validation score: -0.744595\n",
      "Iteration 960, loss = 0.02316764\n",
      "Validation score: -0.439576\n",
      "Iteration 961, loss = 0.01616407\n",
      "Validation score: -1.238002\n",
      "Iteration 962, loss = 0.02858752\n",
      "Validation score: -0.501747\n",
      "Iteration 963, loss = 0.01357309\n",
      "Validation score: -0.901812\n",
      "Iteration 964, loss = 0.03697389\n",
      "Validation score: -1.132120\n",
      "Iteration 965, loss = 0.03699154\n",
      "Validation score: -7.083923\n",
      "Iteration 966, loss = 0.13442678\n",
      "Validation score: -0.398045\n",
      "Iteration 967, loss = 0.01344569\n",
      "Validation score: -15.215930\n",
      "Iteration 968, loss = 0.37497825\n",
      "Validation score: -2.129802\n",
      "Iteration 969, loss = 0.05918818\n",
      "Validation score: -8.079731\n",
      "Iteration 970, loss = 0.17108956\n",
      "Validation score: -6.178412\n",
      "Iteration 971, loss = 0.11706339\n",
      "Validation score: -1.170554\n",
      "Iteration 972, loss = 0.04886336\n",
      "Validation score: -1.539693\n",
      "Iteration 973, loss = 0.04005920\n",
      "Validation score: -0.956732\n",
      "Iteration 974, loss = 0.03144117\n",
      "Validation score: -1.731397\n",
      "Iteration 975, loss = 0.03612475\n",
      "Validation score: -0.451001\n",
      "Iteration 976, loss = 0.02577199\n",
      "Validation score: -0.645458\n",
      "Iteration 977, loss = 0.01900619\n",
      "Validation score: -0.770550\n",
      "Iteration 978, loss = 0.01494241\n",
      "Validation score: -1.685234\n",
      "Iteration 979, loss = 0.04467535\n",
      "Validation score: -0.330673\n",
      "Iteration 980, loss = 0.01914313\n",
      "Validation score: -4.677242\n",
      "Iteration 981, loss = 0.08455570\n",
      "Validation score: -2.583947\n",
      "Iteration 982, loss = 0.04152213\n",
      "Validation score: -0.697313\n",
      "Iteration 983, loss = 0.01742447\n",
      "Validation score: -5.245554\n",
      "Iteration 984, loss = 0.10425440\n",
      "Validation score: -1.883069\n",
      "Iteration 985, loss = 0.04579102\n",
      "Validation score: -1.528300\n",
      "Iteration 986, loss = 0.05374727\n",
      "Validation score: -0.701706\n",
      "Iteration 987, loss = 0.08967332\n",
      "Validation score: -0.658477\n",
      "Iteration 988, loss = 0.05609733\n",
      "Validation score: -2.890956\n",
      "Iteration 989, loss = 0.10726459\n",
      "Validation score: -2.075326\n",
      "Iteration 990, loss = 0.07571339\n",
      "Validation score: -0.361287\n",
      "Iteration 991, loss = 0.03933289\n",
      "Validation score: -0.340774\n",
      "Iteration 992, loss = 0.04105556\n",
      "Validation score: -1.523223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 993, loss = 0.06942213\n",
      "Validation score: -0.447119\n",
      "Iteration 994, loss = 0.03250360\n",
      "Validation score: -1.549123\n",
      "Iteration 995, loss = 0.05835912\n",
      "Validation score: -0.469656\n",
      "Iteration 996, loss = 0.03049582\n",
      "Validation score: -3.451093\n",
      "Iteration 997, loss = 0.10416353\n",
      "Validation score: -0.729457\n",
      "Iteration 998, loss = 0.02284200\n",
      "Validation score: -5.644765\n",
      "Iteration 999, loss = 0.19379703\n",
      "Validation score: -4.415393\n",
      "Iteration 1000, loss = 0.11531444\n",
      "Validation score: -1.813999\n",
      "Iteration 1001, loss = 0.24770547\n",
      "Validation score: -22.629229\n",
      "Iteration 1002, loss = 0.63303621\n",
      "Validation score: -5.109714\n",
      "Iteration 1003, loss = 0.44221977\n",
      "Validation score: -6.440005\n",
      "Iteration 1004, loss = 0.22495278\n",
      "Validation score: -13.549585\n",
      "Iteration 1005, loss = 0.57938214\n",
      "Validation score: -1.647245\n",
      "Iteration 1006, loss = 0.20746617\n",
      "Validation score: -9.950597\n",
      "Iteration 1007, loss = 0.32005794\n",
      "Validation score: -9.849890\n",
      "Iteration 1008, loss = 0.33423177\n",
      "Validation score: -3.060453\n",
      "Iteration 1009, loss = 0.19031459\n",
      "Validation score: -4.047841\n",
      "Iteration 1010, loss = 0.15652090\n",
      "Validation score: -4.075106\n",
      "Iteration 1011, loss = 0.16670645\n",
      "Validation score: -2.019221\n",
      "Iteration 1012, loss = 0.09047340\n",
      "Validation score: -4.231491\n",
      "Iteration 1013, loss = 0.12429905\n",
      "Validation score: -3.445157\n",
      "Iteration 1014, loss = 0.15136823\n",
      "Validation score: -1.395772\n",
      "Iteration 1015, loss = 0.06003593\n",
      "Validation score: -0.909884\n",
      "Iteration 1016, loss = 0.05767078\n",
      "Validation score: -1.712123\n",
      "Iteration 1017, loss = 0.14480989\n",
      "Validation score: -2.574055\n",
      "Iteration 1018, loss = 0.17037914\n",
      "Validation score: -1.503502\n",
      "Iteration 1019, loss = 0.09222429\n",
      "Validation score: -0.757661\n",
      "Iteration 1020, loss = 0.03427019\n",
      "Validation score: -0.787457\n",
      "Iteration 1021, loss = 0.03345405\n",
      "Validation score: -0.731439\n",
      "Iteration 1022, loss = 0.04603233\n",
      "Validation score: -0.918779\n",
      "Iteration 1023, loss = 0.04796262\n",
      "Validation score: -0.918223\n",
      "Iteration 1024, loss = 0.03206755\n",
      "Validation score: -0.660346\n",
      "Iteration 1025, loss = 0.02151580\n",
      "Validation score: -0.463743\n",
      "Iteration 1026, loss = 0.02091910\n",
      "Validation score: -0.437077\n",
      "Iteration 1027, loss = 0.01889307\n",
      "Validation score: -0.479621\n",
      "Iteration 1028, loss = 0.01862846\n",
      "Validation score: -0.366759\n",
      "Iteration 1029, loss = 0.01491023\n",
      "Validation score: -0.368098\n",
      "Iteration 1030, loss = 0.01220262\n",
      "Validation score: -0.448589\n",
      "Iteration 1031, loss = 0.01576204\n",
      "Validation score: -0.415494\n",
      "Iteration 1032, loss = 0.01304458\n",
      "Validation score: -0.333530\n",
      "Iteration 1033, loss = 0.01015435\n",
      "Validation score: -0.501648\n",
      "Iteration 1034, loss = 0.01548341\n",
      "Validation score: -0.558172\n",
      "Iteration 1035, loss = 0.01782199\n",
      "Validation score: -0.407067\n",
      "Iteration 1036, loss = 0.01304684\n",
      "Validation score: -0.366185\n",
      "Iteration 1037, loss = 0.01024573\n",
      "Validation score: -0.482520\n",
      "Iteration 1038, loss = 0.01433561\n",
      "Validation score: -0.428437\n",
      "Iteration 1039, loss = 0.01321819\n",
      "Validation score: -0.393402\n",
      "Iteration 1040, loss = 0.01135639\n",
      "Validation score: -0.429211\n",
      "Iteration 1041, loss = 0.01110179\n",
      "Validation score: -0.461338\n",
      "Iteration 1042, loss = 0.01225407\n",
      "Validation score: -0.481297\n",
      "Iteration 1043, loss = 0.01277425\n",
      "Validation score: -0.366169\n",
      "Iteration 1044, loss = 0.01017551\n",
      "Validation score: -0.440589\n",
      "Iteration 1045, loss = 0.01188949\n",
      "Validation score: -0.386326\n",
      "Iteration 1046, loss = 0.01012629\n",
      "Validation score: -0.423998\n",
      "Iteration 1047, loss = 0.01259240\n",
      "Validation score: -0.388694\n",
      "Iteration 1048, loss = 0.00993406\n",
      "Validation score: -0.545954\n",
      "Iteration 1049, loss = 0.01375083\n",
      "Validation score: -0.557658\n",
      "Iteration 1050, loss = 0.01294853\n",
      "Validation score: -0.348910\n",
      "Iteration 1051, loss = 0.00885808\n",
      "Validation score: -0.627081\n",
      "Iteration 1052, loss = 0.01608089\n",
      "Validation score: -0.504718\n",
      "Iteration 1053, loss = 0.01195043\n",
      "Validation score: -0.380669\n",
      "Iteration 1054, loss = 0.00895047\n",
      "Validation score: -0.629190\n",
      "Iteration 1055, loss = 0.01433453\n",
      "Validation score: -0.396897\n",
      "Iteration 1056, loss = 0.00968340\n",
      "Validation score: -0.578465\n",
      "Iteration 1057, loss = 0.01535023\n",
      "Validation score: -0.433252\n",
      "Iteration 1058, loss = 0.00985133\n",
      "Validation score: -0.744884\n",
      "Iteration 1059, loss = 0.01691288\n",
      "Validation score: -0.943568\n",
      "Iteration 1060, loss = 0.02102606\n",
      "Validation score: -0.395628\n",
      "Iteration 1061, loss = 0.00902169\n",
      "Validation score: -0.399166\n",
      "Iteration 1062, loss = 0.00973233\n",
      "Validation score: -0.417927\n",
      "Iteration 1063, loss = 0.00938243\n",
      "Validation score: -0.363545\n",
      "Iteration 1064, loss = 0.00845495\n",
      "Validation score: -0.457710\n",
      "Iteration 1065, loss = 0.01023347\n",
      "Validation score: -0.411680\n",
      "Iteration 1066, loss = 0.00941736\n",
      "Validation score: -0.354163\n",
      "Iteration 1067, loss = 0.00859685\n",
      "Validation score: -0.404990\n",
      "Iteration 1068, loss = 0.00939044\n",
      "Validation score: -0.378061\n",
      "Iteration 1069, loss = 0.00853778\n",
      "Validation score: -0.351371\n",
      "Iteration 1070, loss = 0.00859149\n",
      "Validation score: -0.351278\n",
      "Iteration 1071, loss = 0.00828342\n",
      "Validation score: -0.391777\n",
      "Iteration 1072, loss = 0.00995449\n",
      "Validation score: -0.365100\n",
      "Iteration 1073, loss = 0.00955570\n",
      "Validation score: -0.444175\n",
      "Iteration 1074, loss = 0.01024406\n",
      "Validation score: -0.372781\n",
      "Iteration 1075, loss = 0.00831479\n",
      "Validation score: -0.452719\n",
      "Iteration 1076, loss = 0.01019154\n",
      "Validation score: -0.400959\n",
      "Iteration 1077, loss = 0.00885515\n",
      "Validation score: -0.365939\n",
      "Iteration 1078, loss = 0.00835268\n",
      "Validation score: -0.395666\n",
      "Iteration 1079, loss = 0.00874369\n",
      "Validation score: -0.354353\n",
      "Iteration 1080, loss = 0.00821682\n",
      "Validation score: -0.372844\n",
      "Iteration 1081, loss = 0.00834135\n",
      "Validation score: -0.369048\n",
      "Iteration 1082, loss = 0.00809977\n",
      "Validation score: -0.367933\n",
      "Iteration 1083, loss = 0.00805775\n",
      "Validation score: -0.361200\n",
      "Iteration 1084, loss = 0.00806138\n",
      "Validation score: -0.368522\n",
      "Iteration 1085, loss = 0.00814041\n",
      "Validation score: -0.377837\n",
      "Iteration 1086, loss = 0.00814359\n",
      "Validation score: -0.378069\n",
      "Iteration 1087, loss = 0.00804653\n",
      "Validation score: -0.370568\n",
      "Iteration 1088, loss = 0.00804226\n",
      "Validation score: -0.366129\n",
      "Iteration 1089, loss = 0.00797474\n",
      "Validation score: -0.381386\n",
      "Iteration 1090, loss = 0.00826691\n",
      "Validation score: -0.377949\n",
      "Iteration 1091, loss = 0.00813671\n",
      "Validation score: -0.363790\n",
      "Iteration 1092, loss = 0.00794046\n",
      "Validation score: -0.363687\n",
      "Iteration 1093, loss = 0.00818474\n",
      "Validation score: -0.356749\n",
      "Iteration 1094, loss = 0.00804052\n",
      "Validation score: -0.362467\n",
      "Iteration 1095, loss = 0.00808625\n",
      "Validation score: -0.358204\n",
      "Iteration 1096, loss = 0.00799653\n",
      "Validation score: -0.358991\n",
      "Iteration 1097, loss = 0.00794076\n",
      "Validation score: -0.358095\n",
      "Iteration 1098, loss = 0.00791464\n",
      "Validation score: -0.360995\n",
      "Iteration 1099, loss = 0.00792725\n",
      "Validation score: -0.367364\n",
      "Iteration 1100, loss = 0.00796541\n",
      "Validation score: -0.368602\n",
      "Iteration 1101, loss = 0.00792162\n",
      "Validation score: -0.361799\n",
      "Iteration 1102, loss = 0.00791408\n",
      "Validation score: -0.354294\n",
      "Iteration 1103, loss = 0.00796066\n",
      "Validation score: -0.354995\n",
      "Iteration 1104, loss = 0.00800135\n",
      "Validation score: -0.358451\n",
      "Iteration 1105, loss = 0.00791779\n",
      "Validation score: -0.367654\n",
      "Iteration 1106, loss = 0.00792155\n",
      "Validation score: -0.373385\n",
      "Iteration 1107, loss = 0.00804434\n",
      "Validation score: -0.372009\n",
      "Iteration 1108, loss = 0.00786895\n",
      "Validation score: -0.368199\n",
      "Iteration 1109, loss = 0.00788484\n",
      "Validation score: -0.370074\n",
      "Iteration 1110, loss = 0.00807828\n",
      "Validation score: -0.370978\n",
      "Iteration 1111, loss = 0.00808448\n",
      "Validation score: -0.370158\n",
      "Iteration 1112, loss = 0.00787988\n",
      "Validation score: -0.362887\n",
      "Iteration 1113, loss = 0.00795371\n",
      "Validation score: -0.357693\n",
      "Iteration 1114, loss = 0.00793742\n",
      "Validation score: -0.361590\n",
      "Iteration 1115, loss = 0.00795020\n",
      "Validation score: -0.366414\n",
      "Iteration 1116, loss = 0.00787462\n",
      "Validation score: -0.369630\n",
      "Iteration 1117, loss = 0.00786321\n",
      "Validation score: -0.367086\n",
      "Iteration 1118, loss = 0.00791756\n",
      "Validation score: -0.360352\n",
      "Iteration 1119, loss = 0.00790427\n",
      "Validation score: -0.358291\n",
      "Iteration 1120, loss = 0.00783861\n",
      "Validation score: -0.362502\n",
      "Iteration 1121, loss = 0.00781438\n",
      "Validation score: -0.368457\n",
      "Iteration 1122, loss = 0.00785050\n",
      "Validation score: -0.370849\n",
      "Iteration 1123, loss = 0.00784200\n",
      "Validation score: -0.369019\n",
      "Iteration 1124, loss = 0.00781933\n",
      "Validation score: -0.370088\n",
      "Iteration 1125, loss = 0.00782064\n",
      "Validation score: -0.375570\n",
      "Iteration 1126, loss = 0.00784577\n",
      "Validation score: -0.378557\n",
      "Iteration 1127, loss = 0.00784277\n",
      "Validation score: -0.377529\n",
      "Iteration 1128, loss = 0.00780395\n",
      "Validation score: -0.374448\n",
      "Iteration 1129, loss = 0.00776924\n",
      "Validation score: -0.371334\n",
      "Iteration 1130, loss = 0.00781873\n",
      "Validation score: -0.368116\n",
      "Iteration 1131, loss = 0.00777319\n",
      "Validation score: -0.370393\n",
      "Iteration 1132, loss = 0.00780219\n",
      "Validation score: -0.372258\n",
      "Iteration 1133, loss = 0.00782153\n",
      "Validation score: -0.374844\n",
      "Iteration 1134, loss = 0.00778482\n",
      "Validation score: -0.378618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1135, loss = 0.00777693\n",
      "Validation score: -0.380381\n",
      "Iteration 1136, loss = 0.00775458\n",
      "Validation score: -0.381540\n",
      "Iteration 1137, loss = 0.00776031\n",
      "Validation score: -0.379923\n",
      "Iteration 1138, loss = 0.00774966\n",
      "Validation score: -0.379518\n",
      "Iteration 1139, loss = 0.00778565\n",
      "Validation score: -0.375492\n",
      "Iteration 1140, loss = 0.00776662\n",
      "Validation score: -0.369534\n",
      "Iteration 1141, loss = 0.00773241\n",
      "Validation score: -0.370937\n",
      "Iteration 1142, loss = 0.00774172\n",
      "Validation score: -0.376316\n",
      "Iteration 1143, loss = 0.00772313\n",
      "Validation score: -0.379463\n",
      "Iteration 1144, loss = 0.00774762\n",
      "Validation score: -0.373111\n",
      "Iteration 1145, loss = 0.00771446\n",
      "Validation score: -0.369138\n",
      "Iteration 1146, loss = 0.00787117\n",
      "Validation score: -0.370245\n",
      "Iteration 1147, loss = 0.00775725\n",
      "Validation score: -0.375458\n",
      "Iteration 1148, loss = 0.00775024\n",
      "Validation score: -0.371688\n",
      "Iteration 1149, loss = 0.00773482\n",
      "Validation score: -0.360305\n",
      "Iteration 1150, loss = 0.00775247\n",
      "Validation score: -0.361585\n",
      "Iteration 1151, loss = 0.00777331\n",
      "Validation score: -0.373648\n",
      "Iteration 1152, loss = 0.00768857\n",
      "Validation score: -0.390257\n",
      "Iteration 1153, loss = 0.00772838\n",
      "Validation score: -0.391324\n",
      "Iteration 1154, loss = 0.00770374\n",
      "Validation score: -0.380996\n",
      "Iteration 1155, loss = 0.00770374\n",
      "Validation score: -0.370352\n",
      "Iteration 1156, loss = 0.00769374\n",
      "Validation score: -0.364490\n",
      "Iteration 1157, loss = 0.00767883\n",
      "Validation score: -0.369582\n",
      "Iteration 1158, loss = 0.00771880\n",
      "Validation score: -0.369174\n",
      "Iteration 1159, loss = 0.00770449\n",
      "Validation score: -0.361229\n",
      "Iteration 1160, loss = 0.00765290\n",
      "Validation score: -0.358325\n",
      "Iteration 1161, loss = 0.00776409\n",
      "Validation score: -0.359441\n",
      "Iteration 1162, loss = 0.00773554\n",
      "Validation score: -0.366698\n",
      "Iteration 1163, loss = 0.00765973\n",
      "Validation score: -0.376460\n",
      "Iteration 1164, loss = 0.00770724\n",
      "Validation score: -0.364864\n",
      "Iteration 1165, loss = 0.00766710\n",
      "Validation score: -0.354753\n",
      "Iteration 1166, loss = 0.00789751\n",
      "Validation score: -0.355733\n",
      "Iteration 1167, loss = 0.00776908\n",
      "Validation score: -0.371461\n",
      "Iteration 1168, loss = 0.00767571\n",
      "Validation score: -0.394150\n",
      "Iteration 1169, loss = 0.00783801\n",
      "Validation score: -0.383085\n",
      "Iteration 1170, loss = 0.00767920\n",
      "Validation score: -0.365428\n",
      "Iteration 1171, loss = 0.00782373\n",
      "Validation score: -0.365586\n",
      "Iteration 1172, loss = 0.00767145\n",
      "Validation score: -0.403475\n",
      "Iteration 1173, loss = 0.00809242\n",
      "Validation score: -0.386653\n",
      "Iteration 1174, loss = 0.00772931\n",
      "Validation score: -0.369677\n",
      "Iteration 1175, loss = 0.00791346\n",
      "Validation score: -0.366811\n",
      "Iteration 1176, loss = 0.00773091\n",
      "Validation score: -0.380652\n",
      "Iteration 1177, loss = 0.00767325\n",
      "Validation score: -0.406038\n",
      "Iteration 1178, loss = 0.00777296\n",
      "Validation score: -0.402482\n",
      "Iteration 1179, loss = 0.00769535\n",
      "Validation score: -0.386157\n",
      "Iteration 1180, loss = 0.00765644\n",
      "Validation score: -0.378716\n",
      "Iteration 1181, loss = 0.00764679\n",
      "Validation score: -0.381039\n",
      "Iteration 1182, loss = 0.00760653\n",
      "Validation score: -0.388769\n",
      "Iteration 1183, loss = 0.00761760\n",
      "Validation score: -0.383439\n",
      "Iteration 1184, loss = 0.00758501\n",
      "Validation score: -0.370912\n",
      "Iteration 1185, loss = 0.00758925\n",
      "Validation score: -0.363087\n",
      "Iteration 1186, loss = 0.00761797\n",
      "Validation score: -0.361311\n",
      "Iteration 1187, loss = 0.00762398\n",
      "Validation score: -0.362884\n",
      "Iteration 1188, loss = 0.00756923\n",
      "Validation score: -0.370138\n",
      "Iteration 1189, loss = 0.00759603\n",
      "Validation score: -0.372950\n",
      "Iteration 1190, loss = 0.00756014\n",
      "Validation score: -0.370801\n",
      "Iteration 1191, loss = 0.00757392\n",
      "Validation score: -0.369976\n",
      "Iteration 1192, loss = 0.00759788\n",
      "Validation score: -0.376246\n",
      "Iteration 1193, loss = 0.00755605\n",
      "Validation score: -0.383054\n",
      "Iteration 1194, loss = 0.00755271\n",
      "Validation score: -0.385156\n",
      "Iteration 1195, loss = 0.00760755\n",
      "Validation score: -0.377856\n",
      "Iteration 1196, loss = 0.00756056\n",
      "Validation score: -0.370209\n",
      "Iteration 1197, loss = 0.00754026\n",
      "Validation score: -0.372092\n",
      "Iteration 1198, loss = 0.00756611\n",
      "Validation score: -0.377670\n",
      "Iteration 1199, loss = 0.00754330\n",
      "Validation score: -0.380339\n",
      "Iteration 1200, loss = 0.00753139\n",
      "Validation score: -0.377490\n",
      "Iteration 1201, loss = 0.00755503\n",
      "Validation score: -0.370222\n",
      "Iteration 1202, loss = 0.00752724\n",
      "Validation score: -0.366083\n",
      "Iteration 1203, loss = 0.00751219\n",
      "Validation score: -0.371979\n",
      "Iteration 1204, loss = 0.00752376\n",
      "Validation score: -0.379819\n",
      "Iteration 1205, loss = 0.00753913\n",
      "Validation score: -0.379769\n",
      "Iteration 1206, loss = 0.00752133\n",
      "Validation score: -0.378043\n",
      "Iteration 1207, loss = 0.00751789\n",
      "Validation score: -0.379444\n",
      "Iteration 1208, loss = 0.00750454\n",
      "Validation score: -0.380769\n",
      "Iteration 1209, loss = 0.00749402\n",
      "Validation score: -0.382718\n",
      "Iteration 1210, loss = 0.00751314\n",
      "Validation score: -0.378314\n",
      "Iteration 1211, loss = 0.00750215\n",
      "Validation score: -0.370872\n",
      "Iteration 1212, loss = 0.00750868\n",
      "Validation score: -0.370516\n",
      "Iteration 1213, loss = 0.00750734\n",
      "Validation score: -0.373249\n",
      "Iteration 1214, loss = 0.00749190\n",
      "Validation score: -0.378450\n",
      "Iteration 1215, loss = 0.00747869\n",
      "Validation score: -0.378741\n",
      "Iteration 1216, loss = 0.00749217\n",
      "Validation score: -0.375720\n",
      "Iteration 1217, loss = 0.00746088\n",
      "Validation score: -0.373441\n",
      "Iteration 1218, loss = 0.00747868\n",
      "Validation score: -0.371721\n",
      "Iteration 1219, loss = 0.00745057\n",
      "Validation score: -0.373069\n",
      "Iteration 1220, loss = 0.00745723\n",
      "Validation score: -0.376932\n",
      "Iteration 1221, loss = 0.00749772\n",
      "Validation score: -0.378924\n",
      "Iteration 1222, loss = 0.00748987\n",
      "Validation score: -0.375408\n",
      "Iteration 1223, loss = 0.00744788\n",
      "Validation score: -0.369505\n",
      "Iteration 1224, loss = 0.00744222\n",
      "Validation score: -0.366794\n",
      "Iteration 1225, loss = 0.00746276\n",
      "Validation score: -0.369965\n",
      "Iteration 1226, loss = 0.00745107\n",
      "Validation score: -0.378255\n",
      "Iteration 1227, loss = 0.00744860\n",
      "Validation score: -0.384572\n",
      "Iteration 1228, loss = 0.00741844\n",
      "Validation score: -0.385121\n",
      "Iteration 1229, loss = 0.00744566\n",
      "Validation score: -0.382546\n",
      "Iteration 1230, loss = 0.00743885\n",
      "Validation score: -0.381294\n",
      "Iteration 1231, loss = 0.00744916\n",
      "Validation score: -0.383561\n",
      "Iteration 1232, loss = 0.00743836\n",
      "Validation score: -0.385410\n",
      "Iteration 1233, loss = 0.00743763\n",
      "Validation score: -0.386481\n",
      "Iteration 1234, loss = 0.00742145\n",
      "Validation score: -0.387754\n",
      "Iteration 1235, loss = 0.00742249\n",
      "Validation score: -0.388954\n",
      "Iteration 1236, loss = 0.00742596\n",
      "Validation score: -0.391165\n",
      "Iteration 1237, loss = 0.00741711\n",
      "Validation score: -0.390836\n",
      "Iteration 1238, loss = 0.00743818\n",
      "Validation score: -0.386207\n",
      "Iteration 1239, loss = 0.00740760\n",
      "Validation score: -0.381808\n",
      "Iteration 1240, loss = 0.01013624\n",
      "Validation score: -0.429886\n",
      "Iteration 1241, loss = 0.00789530\n",
      "Validation score: -0.513989\n",
      "Iteration 1242, loss = 0.00917016\n",
      "Validation score: -0.471223\n",
      "Iteration 1243, loss = 0.00826960\n",
      "Validation score: -0.408949\n",
      "Iteration 1244, loss = 0.00777950\n",
      "Validation score: -0.403790\n",
      "Iteration 1245, loss = 0.00811278\n",
      "Validation score: -0.417920\n",
      "Iteration 1246, loss = 0.00815051\n",
      "Validation score: -0.426593\n",
      "Iteration 1247, loss = 0.00823547\n",
      "Validation score: -0.419355\n",
      "Iteration 1248, loss = 0.00808536\n",
      "Validation score: -0.408609\n",
      "Iteration 1249, loss = 0.00779826\n",
      "Validation score: -0.395194\n",
      "Iteration 1250, loss = 0.00758332\n",
      "Validation score: -0.392255\n",
      "Iteration 1251, loss = 0.00772426\n",
      "Validation score: -0.379659\n",
      "Iteration 1252, loss = 0.00765024\n",
      "Validation score: -0.387695\n",
      "Iteration 1253, loss = 0.00778753\n",
      "Validation score: -0.387782\n",
      "Iteration 1254, loss = 0.00749858\n",
      "Validation score: -0.390045\n",
      "Iteration 1255, loss = 0.00758550\n",
      "Validation score: -0.384976\n",
      "Iteration 1256, loss = 0.00749307\n",
      "Validation score: -0.387387\n",
      "Iteration 1257, loss = 0.00776850\n",
      "Validation score: -0.392815\n",
      "Iteration 1258, loss = 0.00758585\n",
      "Validation score: -0.399621\n",
      "Iteration 1259, loss = 0.00758168\n",
      "Validation score: -0.381791\n",
      "Iteration 1260, loss = 0.00741326\n",
      "Validation score: -0.363334\n",
      "Iteration 1261, loss = 0.00748418\n",
      "Validation score: -0.367536\n",
      "Iteration 1262, loss = 0.00747559\n",
      "Validation score: -0.380630\n",
      "Iteration 1263, loss = 0.00743516\n",
      "Validation score: -0.385892\n",
      "Iteration 1264, loss = 0.00740060\n",
      "Validation score: -0.384561\n",
      "Iteration 1265, loss = 0.00737212\n",
      "Validation score: -0.381982\n",
      "Iteration 1266, loss = 0.00748190\n",
      "Validation score: -0.386174\n",
      "Iteration 1267, loss = 0.00741226\n",
      "Validation score: -0.385855\n",
      "Iteration 1268, loss = 0.00754665\n",
      "Validation score: -0.389911\n",
      "Iteration 1269, loss = 0.00775883\n",
      "Validation score: -0.393294\n",
      "Iteration 1270, loss = 0.00753345\n",
      "Validation score: -0.391171\n",
      "Iteration 1271, loss = 0.00737327\n",
      "Validation score: -0.387531\n",
      "Iteration 1272, loss = 0.00738998\n",
      "Validation score: -0.382940\n",
      "Iteration 1273, loss = 0.00737389\n",
      "Validation score: -0.378358\n",
      "Iteration 1274, loss = 0.00735012\n",
      "Validation score: -0.382226\n",
      "Iteration 1275, loss = 0.00749204\n",
      "Validation score: -0.384768\n",
      "Iteration 1276, loss = 0.00731531\n",
      "Validation score: -0.399250\n",
      "Iteration 1277, loss = 0.00759369\n",
      "Validation score: -0.402760\n",
      "Iteration 1278, loss = 0.00765606\n",
      "Validation score: -0.391043\n",
      "Iteration 1279, loss = 0.00736715\n",
      "Validation score: -0.388510\n",
      "Iteration 1280, loss = 0.00749806\n",
      "Validation score: -0.378605\n",
      "Iteration 1281, loss = 0.00732882\n",
      "Validation score: -0.394007\n",
      "Iteration 1282, loss = 0.00771968\n",
      "Validation score: -0.401509\n",
      "Iteration 1283, loss = 0.00766021\n",
      "Validation score: -0.390112\n",
      "Iteration 1284, loss = 0.00728814\n",
      "Validation score: -0.392598\n",
      "Iteration 1285, loss = 0.00748725\n",
      "Validation score: -0.386877\n",
      "Iteration 1286, loss = 0.00739739\n",
      "Validation score: -0.375920\n",
      "Iteration 1287, loss = 0.00732272\n",
      "Validation score: -0.392631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1288, loss = 0.00765108\n",
      "Validation score: -0.401173\n",
      "Iteration 1289, loss = 0.00741325\n",
      "Validation score: -0.398345\n",
      "Iteration 1290, loss = 0.00780688\n",
      "Validation score: -0.395122\n",
      "Iteration 1291, loss = 0.00743413\n",
      "Validation score: -0.378000\n",
      "Iteration 1292, loss = 0.00783392\n",
      "Validation score: -0.379258\n",
      "Iteration 1293, loss = 0.00885411\n",
      "Validation score: -0.374878\n",
      "Iteration 1294, loss = 0.00767567\n",
      "Validation score: -0.394689\n",
      "Iteration 1295, loss = 0.00758987\n",
      "Validation score: -0.400012\n",
      "Iteration 1296, loss = 0.00918013\n",
      "Validation score: -0.387950\n",
      "Iteration 1297, loss = 0.00914610\n",
      "Validation score: -0.401168\n",
      "Iteration 1298, loss = 0.00799566\n",
      "Validation score: -0.389718\n",
      "Iteration 1299, loss = 0.00766794\n",
      "Validation score: -0.377782\n",
      "Iteration 1300, loss = 0.00874044\n",
      "Validation score: -0.393199\n",
      "Iteration 1301, loss = 0.00819991\n",
      "Validation score: -0.378685\n",
      "Iteration 1302, loss = 0.00795900\n",
      "Validation score: -0.419553\n",
      "Iteration 1303, loss = 0.00903716\n",
      "Validation score: -0.414817\n",
      "Iteration 1304, loss = 0.00842440\n",
      "Validation score: -0.385401\n",
      "Iteration 1305, loss = 0.00743853\n",
      "Validation score: -0.411028\n",
      "Iteration 1306, loss = 0.00834757\n",
      "Validation score: -0.377791\n",
      "Iteration 1307, loss = 0.00754825\n",
      "Validation score: -0.395187\n",
      "Iteration 1308, loss = 0.00779117\n",
      "Validation score: -0.397707\n",
      "Iteration 1309, loss = 0.00758934\n",
      "Validation score: -0.404104\n",
      "Iteration 1310, loss = 0.00752094\n",
      "Validation score: -0.397758\n",
      "Iteration 1311, loss = 0.00738749\n",
      "Validation score: -0.388361\n",
      "Iteration 1312, loss = 0.00733249\n",
      "Validation score: -0.406194\n",
      "Iteration 1313, loss = 0.00751235\n",
      "Validation score: -0.402634\n",
      "Iteration 1314, loss = 0.00739753\n",
      "Validation score: -0.388590\n",
      "Iteration 1315, loss = 0.00723766\n",
      "Validation score: -0.411799\n",
      "Iteration 1316, loss = 0.00771250\n",
      "Validation score: -0.401836\n",
      "Iteration 1317, loss = 0.00738747\n",
      "Validation score: -0.404254\n",
      "Iteration 1318, loss = 0.00737018\n",
      "Validation score: -0.392214\n",
      "Iteration 1319, loss = 0.00723853\n",
      "Validation score: -0.393021\n",
      "Iteration 1320, loss = 0.00761198\n",
      "Validation score: -0.374461\n",
      "Iteration 1321, loss = 0.00735936\n",
      "Validation score: -0.407064\n",
      "Iteration 1322, loss = 0.00794797\n",
      "Validation score: -0.403287\n",
      "Iteration 1323, loss = 0.00762836\n",
      "Validation score: -0.390325\n",
      "Iteration 1324, loss = 0.00742092\n",
      "Validation score: -0.386922\n",
      "Iteration 1325, loss = 0.00739265\n",
      "Validation score: -0.386613\n",
      "Iteration 1326, loss = 0.00724418\n",
      "Validation score: -0.396933\n",
      "Iteration 1327, loss = 0.00752494\n",
      "Validation score: -0.386154\n",
      "Iteration 1328, loss = 0.00755683\n",
      "Validation score: -0.397492\n",
      "Iteration 1329, loss = 0.00766228\n",
      "Validation score: -0.382410\n",
      "Iteration 1330, loss = 0.00717293\n",
      "Validation score: -0.417546\n",
      "Iteration 1331, loss = 0.00786291\n",
      "Validation score: -0.407216\n",
      "Iteration 1332, loss = 0.00750061\n",
      "Validation score: -0.392229\n",
      "Iteration 1333, loss = 0.00736441\n",
      "Validation score: -0.398658\n",
      "Iteration 1334, loss = 0.00758492\n",
      "Validation score: -0.384797\n",
      "Iteration 1335, loss = 0.00713896\n",
      "Validation score: -0.393687\n",
      "Iteration 1336, loss = 0.00734980\n",
      "Validation score: -0.391748\n",
      "Iteration 1337, loss = 0.00728127\n",
      "Validation score: -0.388551\n",
      "Iteration 1338, loss = 0.00712222\n",
      "Validation score: -0.389816\n",
      "Iteration 1339, loss = 0.00745802\n",
      "Validation score: -0.385623\n",
      "Iteration 1340, loss = 0.00744445\n",
      "Validation score: -0.386570\n",
      "Iteration 1341, loss = 0.00710874\n",
      "Validation score: -0.383993\n",
      "Iteration 1342, loss = 0.00711337\n",
      "Validation score: -0.382651\n",
      "Iteration 1343, loss = 0.00729450\n",
      "Validation score: -0.386099\n",
      "Iteration 1344, loss = 0.00711344\n",
      "Validation score: -0.388932\n",
      "Iteration 1345, loss = 0.00765786\n",
      "Validation score: -0.388438\n",
      "Iteration 1346, loss = 0.00716375\n",
      "Validation score: -0.389005\n",
      "Iteration 1347, loss = 0.00728982\n",
      "Validation score: -0.391514\n",
      "Iteration 1348, loss = 0.00731456\n",
      "Validation score: -0.396957\n",
      "Iteration 1349, loss = 0.00728520\n",
      "Validation score: -0.390643\n",
      "Iteration 1350, loss = 0.00720085\n",
      "Validation score: -0.377814\n",
      "Iteration 1351, loss = 0.00707074\n",
      "Validation score: -0.374619\n",
      "Iteration 1352, loss = 0.00765662\n",
      "Validation score: -0.383157\n",
      "Iteration 1353, loss = 0.00785018\n",
      "Validation score: -0.394304\n",
      "Iteration 1354, loss = 0.00706489\n",
      "Validation score: -0.403340\n",
      "Iteration 1355, loss = 0.00942317\n",
      "Validation score: -0.396344\n",
      "Iteration 1356, loss = 0.00964717\n",
      "Validation score: -0.393776\n",
      "Iteration 1357, loss = 0.00731069\n",
      "Validation score: -0.391427\n",
      "Iteration 1358, loss = 0.00836143\n",
      "Validation score: -0.396118\n",
      "Iteration 1359, loss = 0.00736365\n",
      "Validation score: -0.394445\n",
      "Iteration 1360, loss = 0.00933966\n",
      "Validation score: -0.409133\n",
      "Iteration 1361, loss = 0.00761318\n",
      "Validation score: -0.391193\n",
      "Iteration 1362, loss = 0.01407465\n",
      "Validation score: -0.439302\n",
      "Iteration 1363, loss = 0.00840279\n",
      "Validation score: -0.465120\n",
      "Iteration 1364, loss = 0.01646089\n",
      "Validation score: -0.409462\n",
      "Iteration 1365, loss = 0.02410765\n",
      "Validation score: -0.467763\n",
      "Iteration 1366, loss = 0.01327539\n",
      "Validation score: -0.459765\n",
      "Iteration 1367, loss = 0.00923551\n",
      "Validation score: -0.415627\n",
      "Iteration 1368, loss = 0.02658067\n",
      "Validation score: -0.425774\n",
      "Iteration 1369, loss = 0.03182939\n",
      "Validation score: -0.458880\n",
      "Iteration 1370, loss = 0.01198269\n",
      "Validation score: -0.441614\n",
      "Iteration 1371, loss = 0.00882702\n",
      "Validation score: -0.773405\n",
      "Iteration 1372, loss = 0.04050679\n",
      "Validation score: -0.506640\n",
      "Iteration 1373, loss = 0.03159261\n",
      "Validation score: -1.506862\n",
      "Iteration 1374, loss = 0.04324085\n",
      "Validation score: -0.603538\n",
      "Iteration 1375, loss = 0.01945000\n",
      "Validation score: -3.149365\n",
      "Iteration 1376, loss = 0.08117552\n",
      "Validation score: -1.456818\n",
      "Iteration 1377, loss = 0.04514796\n",
      "Validation score: -1.186996\n",
      "Iteration 1378, loss = 0.05004005\n",
      "Validation score: -0.549142\n",
      "Iteration 1379, loss = 0.01318136\n",
      "Validation score: -3.106454\n",
      "Iteration 1380, loss = 0.08127714\n",
      "Validation score: -2.067870\n",
      "Iteration 1381, loss = 0.10461233\n",
      "Validation score: -0.660111\n",
      "Iteration 1382, loss = 0.01949617\n",
      "Validation score: -2.004874\n",
      "Iteration 1383, loss = 0.10911470\n",
      "Validation score: -0.502545\n",
      "Iteration 1384, loss = 0.22697297\n",
      "Validation score: -1.729218\n",
      "Iteration 1385, loss = 0.07005887\n",
      "Validation score: -0.617953\n",
      "Iteration 1386, loss = 0.12243504\n",
      "Validation score: -2.725181\n",
      "Iteration 1387, loss = 0.42524614\n",
      "Validation score: -0.761822\n",
      "Iteration 1388, loss = 0.32664912\n",
      "Validation score: -1.720372\n",
      "Iteration 1389, loss = 0.11919255\n",
      "Validation score: -1.894973\n",
      "Iteration 1390, loss = 0.05464514\n",
      "Validation score: -0.643990\n",
      "Iteration 1391, loss = 0.11053312\n",
      "Validation score: -1.457863\n",
      "Iteration 1392, loss = 0.16331273\n",
      "Validation score: -0.958886\n",
      "Iteration 1393, loss = 0.10183543\n",
      "Validation score: -0.650696\n",
      "Iteration 1394, loss = 0.03850496\n",
      "Validation score: -0.453221\n",
      "Iteration 1395, loss = 0.02994691\n",
      "Validation score: -0.942111\n",
      "Iteration 1396, loss = 0.06200688\n",
      "Validation score: -0.722434\n",
      "Iteration 1397, loss = 0.06460011\n",
      "Validation score: -1.276384\n",
      "Iteration 1398, loss = 0.05825880\n",
      "Validation score: -0.476033\n",
      "Iteration 1399, loss = 0.01894411\n",
      "Validation score: -0.759692\n",
      "Iteration 1400, loss = 0.02173846\n",
      "Validation score: -0.800533\n",
      "Iteration 1401, loss = 0.02900664\n",
      "Validation score: -0.487949\n",
      "Iteration 1402, loss = 0.02561946\n",
      "Validation score: -0.768631\n",
      "Iteration 1403, loss = 0.02883413\n",
      "Validation score: -0.428172\n",
      "Iteration 1404, loss = 0.01194708\n",
      "Validation score: -1.333873\n",
      "Iteration 1405, loss = 0.03110598\n",
      "Validation score: -0.837550\n",
      "Iteration 1406, loss = 0.01986362\n",
      "Validation score: -0.538438\n",
      "Iteration 1407, loss = 0.01700387\n",
      "Validation score: -1.314825\n",
      "Iteration 1408, loss = 0.03342869\n",
      "Validation score: -0.527494\n",
      "Iteration 1409, loss = 0.01254538\n",
      "Validation score: -0.692676\n",
      "Iteration 1410, loss = 0.01833463\n",
      "Validation score: -0.440052\n",
      "Iteration 1411, loss = 0.00982041\n",
      "Validation score: -1.042580\n",
      "Iteration 1412, loss = 0.02398697\n",
      "Validation score: -0.825929\n",
      "Iteration 1413, loss = 0.01707788\n",
      "Validation score: -0.462243\n",
      "Iteration 1414, loss = 0.01823293\n",
      "Validation score: -0.425770\n",
      "Iteration 1415, loss = 0.00825995\n",
      "Validation score: -2.133254\n",
      "Iteration 1416, loss = 0.04642214\n",
      "Validation score: -0.450441\n",
      "Iteration 1417, loss = 0.00833803\n",
      "Validation score: -4.789295\n",
      "Iteration 1418, loss = 0.13285276\n",
      "Validation score: -0.460281\n",
      "Iteration 1419, loss = 0.01747958\n",
      "Validation score: -12.350023\n",
      "Iteration 1420, loss = 0.27540925\n",
      "Validation score: -6.268257\n",
      "Iteration 1421, loss = 0.14398388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: -1.953134\n",
      "Iteration 1422, loss = 0.04890237\n",
      "Validation score: -7.729849\n",
      "Iteration 1423, loss = 0.16104432\n",
      "Validation score: -0.432913\n",
      "Iteration 1424, loss = 0.06175164\n",
      "Validation score: -7.568161\n",
      "Iteration 1425, loss = 0.16522578\n",
      "Validation score: -1.252800\n",
      "Iteration 1426, loss = 0.02726699\n",
      "Validation score: -2.486501\n",
      "Iteration 1427, loss = 0.05541644\n",
      "Validation score: -4.392256\n",
      "Iteration 1428, loss = 0.09025815\n",
      "Validation score: -0.683824\n",
      "Iteration 1429, loss = 0.01807471\n",
      "Validation score: -1.947394\n",
      "Iteration 1430, loss = 0.04814031\n",
      "Validation score: -0.755413\n",
      "Iteration 1431, loss = 0.01631719\n",
      "Validation score: -2.079633\n",
      "Iteration 1432, loss = 0.08759880\n",
      "Validation score: -0.475964\n",
      "Iteration 1433, loss = 0.01220838\n",
      "Validation score: -8.951385\n",
      "Iteration 1434, loss = 0.20499683\n",
      "Validation score: -8.181297\n",
      "Iteration 1435, loss = 0.17969989\n",
      "Validation score: -0.588375\n",
      "Iteration 1436, loss = 0.02157168\n",
      "Validation score: -2.360379\n",
      "Iteration 1437, loss = 0.07473150\n",
      "Validation score: -0.509998\n",
      "Iteration 1438, loss = 0.00970108\n",
      "Validation score: -9.263823\n",
      "Iteration 1439, loss = 0.21478603\n",
      "Validation score: -9.807050\n",
      "Iteration 1440, loss = 0.19533198\n",
      "Validation score: -0.540221\n",
      "Iteration 1441, loss = 0.01838756\n",
      "Validation score: -11.882198\n",
      "Iteration 1442, loss = 0.27751871\n",
      "Validation score: -13.647392\n",
      "Iteration 1443, loss = 0.26870699\n",
      "Validation score: -0.930841\n",
      "Iteration 1444, loss = 0.03631689\n",
      "Validation score: -7.934230\n",
      "Iteration 1445, loss = 0.24681082\n",
      "Validation score: -3.573798\n",
      "Iteration 1446, loss = 0.09081458\n",
      "Validation score: -6.195409\n",
      "Iteration 1447, loss = 0.16618581\n",
      "Validation score: -9.989422\n",
      "Iteration 1448, loss = 0.19849436\n",
      "Validation score: -1.531422\n",
      "Iteration 1449, loss = 0.03713358\n",
      "Validation score: -5.213660\n",
      "Iteration 1450, loss = 0.12932916\n",
      "Validation score: -4.066459\n",
      "Iteration 1451, loss = 0.07777465\n",
      "Validation score: -2.052721\n",
      "Iteration 1452, loss = 0.03719583\n",
      "Validation score: -6.526745\n",
      "Iteration 1453, loss = 0.11964506\n",
      "Validation score: -3.477603\n",
      "Iteration 1454, loss = 0.06678545\n",
      "Validation score: -1.629299\n",
      "Iteration 1455, loss = 0.03988936\n",
      "Validation score: -4.804031\n",
      "Iteration 1456, loss = 0.09743766\n",
      "Validation score: -2.125499\n",
      "Iteration 1457, loss = 0.02876236\n",
      "Validation score: -1.080067\n",
      "Iteration 1458, loss = 0.03544976\n",
      "Validation score: -2.688581\n",
      "Iteration 1459, loss = 0.05109002\n",
      "Validation score: -1.683707\n",
      "Iteration 1460, loss = 0.03518142\n",
      "Validation score: -0.903247\n",
      "Iteration 1461, loss = 0.01957900\n",
      "Validation score: -0.718550\n",
      "Iteration 1462, loss = 0.01701401\n",
      "Validation score: -2.092023\n",
      "Iteration 1463, loss = 0.04085851\n",
      "Validation score: -2.004747\n",
      "Iteration 1464, loss = 0.03568686\n",
      "Validation score: -0.666209\n",
      "Iteration 1465, loss = 0.01217041\n",
      "Validation score: -0.891375\n",
      "Iteration 1466, loss = 0.01959934\n",
      "Validation score: -1.297140\n",
      "Iteration 1467, loss = 0.02633857\n",
      "Validation score: -0.737697\n",
      "Iteration 1468, loss = 0.01353054\n",
      "Validation score: -0.471943\n",
      "Iteration 1469, loss = 0.00898098\n",
      "Validation score: -0.760921\n",
      "Iteration 1470, loss = 0.01564564\n",
      "Validation score: -0.528823\n",
      "Iteration 1471, loss = 0.01065750\n",
      "Validation score: -0.507433\n",
      "Iteration 1472, loss = 0.01008647\n",
      "Validation score: -0.852014\n",
      "Iteration 1473, loss = 0.01701379\n",
      "Validation score: -0.499688\n",
      "Iteration 1474, loss = 0.00959414\n",
      "Validation score: -0.607337\n",
      "Iteration 1475, loss = 0.01424921\n",
      "Validation score: -0.722795\n",
      "Iteration 1476, loss = 0.01160697\n",
      "Validation score: -0.425495\n",
      "Iteration 1477, loss = 0.00980801\n",
      "Validation score: -0.949982\n",
      "Iteration 1478, loss = 0.01857822\n",
      "Validation score: -0.747949\n",
      "Iteration 1479, loss = 0.01490659\n",
      "Validation score: -0.434048\n",
      "Iteration 1480, loss = 0.00841923\n",
      "Validation score: -0.470712\n",
      "Iteration 1481, loss = 0.00927497\n",
      "Validation score: -0.452137\n",
      "Iteration 1482, loss = 0.00839288\n",
      "Validation score: -0.470254\n",
      "Iteration 1483, loss = 0.00826596\n",
      "Validation score: -0.539290\n",
      "Iteration 1484, loss = 0.00946092\n",
      "Validation score: -0.425888\n",
      "Iteration 1485, loss = 0.00744930\n",
      "Validation score: -0.435821\n",
      "Iteration 1486, loss = 0.00839662\n",
      "Validation score: -0.457064\n",
      "Iteration 1487, loss = 0.00792197\n",
      "Validation score: -0.392850\n",
      "Iteration 1488, loss = 0.00737796\n",
      "Validation score: -0.440511\n",
      "Iteration 1489, loss = 0.00778508\n",
      "Validation score: -0.425077\n",
      "Iteration 1490, loss = 0.00752184\n",
      "Validation score: -0.397818\n",
      "Iteration 1491, loss = 0.00729036\n",
      "Validation score: -0.391127\n",
      "Iteration 1492, loss = 0.00720131\n",
      "Validation score: -0.393876\n",
      "Iteration 1493, loss = 0.00717128\n",
      "Validation score: -0.387119\n",
      "Iteration 1494, loss = 0.00711255\n",
      "Validation score: -0.392598\n",
      "Iteration 1495, loss = 0.00700274\n",
      "Validation score: -0.399430\n",
      "Iteration 1496, loss = 0.00717200\n",
      "Validation score: -0.391375\n",
      "Iteration 1497, loss = 0.00715363\n",
      "Validation score: -0.389127\n",
      "Iteration 1498, loss = 0.00711774\n",
      "Validation score: -0.398091\n",
      "Iteration 1499, loss = 0.00701382\n",
      "Validation score: -0.395590\n",
      "Iteration 1500, loss = 0.00734185\n",
      "Validation score: -0.395918\n",
      "Iteration 1501, loss = 0.00780729\n",
      "Validation score: -0.387580\n",
      "Iteration 1502, loss = 0.00730343\n",
      "Validation score: -0.383358\n",
      "Iteration 1503, loss = 0.00694790\n",
      "Validation score: -0.392066\n",
      "Iteration 1504, loss = 0.00704650\n",
      "Validation score: -0.398548\n",
      "Iteration 1505, loss = 0.00696058\n",
      "Validation score: -0.402827\n",
      "Iteration 1506, loss = 0.00690004\n",
      "Validation score: -0.401558\n",
      "Iteration 1507, loss = 0.00692265\n",
      "Validation score: -0.393522\n",
      "Iteration 1508, loss = 0.00694206\n",
      "Validation score: -0.388386\n",
      "Iteration 1509, loss = 0.00685358\n",
      "Validation score: -0.401935\n",
      "Iteration 1510, loss = 0.00699899\n",
      "Validation score: -0.406581\n",
      "Iteration 1511, loss = 0.00696729\n",
      "Validation score: -0.399622\n",
      "Iteration 1512, loss = 0.00684560\n",
      "Validation score: -0.395526\n",
      "Iteration 1513, loss = 0.00693343\n",
      "Validation score: -0.390940\n",
      "Iteration 1514, loss = 0.00682270\n",
      "Validation score: -0.387362\n",
      "Iteration 1515, loss = 0.00687587\n",
      "Validation score: -0.390474\n",
      "Iteration 1516, loss = 0.00712398\n",
      "Validation score: -0.390964\n",
      "Iteration 1517, loss = 0.00689648\n",
      "Validation score: -0.392695\n",
      "Iteration 1518, loss = 0.00694501\n",
      "Validation score: -0.393325\n",
      "Iteration 1519, loss = 0.00699097\n",
      "Validation score: -0.386825\n",
      "Iteration 1520, loss = 0.00688812\n",
      "Validation score: -0.382483\n",
      "Iteration 1521, loss = 0.00683366\n",
      "Validation score: -0.386166\n",
      "Iteration 1522, loss = 0.00686017\n",
      "Validation score: -0.393959\n",
      "Iteration 1523, loss = 0.00682466\n",
      "Validation score: -0.402842\n",
      "Iteration 1524, loss = 0.00682903\n",
      "Validation score: -0.403243\n",
      "Iteration 1525, loss = 0.00677471\n",
      "Validation score: -0.398645\n",
      "Iteration 1526, loss = 0.00683690\n",
      "Validation score: -0.395767\n",
      "Iteration 1527, loss = 0.00689048\n",
      "Validation score: -0.394090\n",
      "Iteration 1528, loss = 0.00681893\n",
      "Validation score: -0.394002\n",
      "Iteration 1529, loss = 0.00677107\n",
      "Validation score: -0.394202\n",
      "Iteration 1530, loss = 0.00678053\n",
      "Validation score: -0.395316\n",
      "Iteration 1531, loss = 0.00675811\n",
      "Validation score: -0.398236\n",
      "Iteration 1532, loss = 0.00676464\n",
      "Validation score: -0.397344\n",
      "Iteration 1533, loss = 0.00678160\n",
      "Validation score: -0.393027\n",
      "Iteration 1534, loss = 0.00675638\n",
      "Validation score: -0.389788\n",
      "Iteration 1535, loss = 0.00673101\n",
      "Validation score: -0.386883\n",
      "Iteration 1536, loss = 0.00677623\n",
      "Validation score: -0.388464\n",
      "Iteration 1537, loss = 0.00681235\n",
      "Validation score: -0.395776\n",
      "Iteration 1538, loss = 0.00679680\n",
      "Validation score: -0.400200\n",
      "Iteration 1539, loss = 0.00672077\n",
      "Validation score: -0.397522\n",
      "Iteration 1540, loss = 0.00672865\n",
      "Validation score: -0.389420\n",
      "Iteration 1541, loss = 0.00674462\n",
      "Validation score: -0.383523\n",
      "Iteration 1542, loss = 0.00672263\n",
      "Validation score: -0.383658\n",
      "Iteration 1543, loss = 0.00670999\n",
      "Validation score: -0.391414\n",
      "Iteration 1544, loss = 0.00672116\n",
      "Validation score: -0.398738\n",
      "Iteration 1545, loss = 0.00670506\n",
      "Validation score: -0.400560\n",
      "Iteration 1546, loss = 0.00670145\n",
      "Validation score: -0.398850\n",
      "Iteration 1547, loss = 0.00671074\n",
      "Validation score: -0.398252\n",
      "Iteration 1548, loss = 0.00667043\n",
      "Validation score: -0.404075\n",
      "Iteration 1549, loss = 0.00677059\n",
      "Validation score: -0.403690\n",
      "Iteration 1550, loss = 0.00678806\n",
      "Validation score: -0.396598\n",
      "Iteration 1551, loss = 0.00669349\n",
      "Validation score: -0.389912\n",
      "Iteration 1552, loss = 0.00669694\n",
      "Validation score: -0.386352\n",
      "Iteration 1553, loss = 0.00670269\n",
      "Validation score: -0.388212\n",
      "Iteration 1554, loss = 0.00667021\n",
      "Validation score: -0.398654\n",
      "Iteration 1555, loss = 0.00675887\n",
      "Validation score: -0.401113\n",
      "Iteration 1556, loss = 0.00668629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: -0.397650\n",
      "Iteration 1557, loss = 0.00672581\n",
      "Validation score: -0.393386\n",
      "Iteration 1558, loss = 0.00677108\n",
      "Validation score: -0.391723\n",
      "Iteration 1559, loss = 0.00667877\n",
      "Validation score: -0.399144\n",
      "Iteration 1560, loss = 0.00669300\n",
      "Validation score: -0.406840\n",
      "Iteration 1561, loss = 0.00665968\n",
      "Validation score: -0.411575\n",
      "Iteration 1562, loss = 0.00670890\n",
      "Validation score: -0.405136\n",
      "Iteration 1563, loss = 0.00673395\n",
      "Validation score: -0.392729\n",
      "Iteration 1564, loss = 0.00667474\n",
      "Validation score: -0.399190\n",
      "Iteration 1565, loss = 0.00673146\n",
      "Validation score: -0.407898\n",
      "Iteration 1566, loss = 0.00663217\n",
      "Validation score: -0.411310\n",
      "Iteration 1567, loss = 0.00669937\n",
      "Validation score: -0.401676\n",
      "Iteration 1568, loss = 0.00673420\n",
      "Validation score: -0.392810\n",
      "Iteration 1569, loss = 0.00665276\n",
      "Validation score: -0.395393\n",
      "Iteration 1570, loss = 0.00662652\n",
      "Validation score: -0.403973\n",
      "Iteration 1571, loss = 0.00672002\n",
      "Validation score: -0.394930\n",
      "Iteration 1572, loss = 0.00660901\n",
      "Validation score: -0.391764\n",
      "Iteration 1573, loss = 0.00691958\n",
      "Validation score: -0.394405\n",
      "Iteration 1574, loss = 0.00689473\n",
      "Validation score: -0.397686\n",
      "Iteration 1575, loss = 0.00664128\n",
      "Validation score: -0.410266\n",
      "Iteration 1576, loss = 0.00688920\n",
      "Validation score: -0.403584\n",
      "Iteration 1577, loss = 0.00681913\n",
      "Validation score: -0.391544\n",
      "Iteration 1578, loss = 0.00687687\n",
      "Validation score: -0.395721\n",
      "Iteration 1579, loss = 0.00668664\n",
      "Validation score: -0.413822\n",
      "Iteration 1580, loss = 0.00672020\n",
      "Validation score: -0.407959\n",
      "Iteration 1581, loss = 0.00666482\n",
      "Validation score: -0.393187\n",
      "Iteration 1582, loss = 0.00669562\n",
      "Validation score: -0.393521\n",
      "Iteration 1583, loss = 0.00676642\n",
      "Validation score: -0.402476\n",
      "Iteration 1584, loss = 0.00662005\n",
      "Validation score: -0.423641\n",
      "Iteration 1585, loss = 0.00665293\n",
      "Validation score: -0.432006\n",
      "Iteration 1586, loss = 0.00681290\n",
      "Validation score: -0.407391\n",
      "Iteration 1587, loss = 0.00658831\n",
      "Validation score: -0.389574\n",
      "Iteration 1588, loss = 0.00686831\n",
      "Validation score: -0.389677\n",
      "Iteration 1589, loss = 0.00687599\n",
      "Validation score: -0.398563\n",
      "Iteration 1590, loss = 0.00661724\n",
      "Validation score: -0.439182\n",
      "Iteration 1591, loss = 0.00710301\n",
      "Validation score: -0.438822\n",
      "Iteration 1592, loss = 0.00690993\n",
      "Validation score: -0.397012\n",
      "Iteration 1593, loss = 0.00678797\n",
      "Validation score: -0.388981\n",
      "Iteration 1594, loss = 0.00769352\n",
      "Validation score: -0.387959\n",
      "Iteration 1595, loss = 0.00686705\n",
      "Validation score: -0.440500\n",
      "Iteration 1596, loss = 0.00700614\n",
      "Validation score: -0.485319\n",
      "Iteration 1597, loss = 0.00827539\n",
      "Validation score: -0.440117\n",
      "Iteration 1598, loss = 0.00696155\n",
      "Validation score: -0.400334\n",
      "Iteration 1599, loss = 0.00829265\n",
      "Validation score: -0.396023\n",
      "Iteration 1600, loss = 0.00693000\n",
      "Validation score: -0.410758\n",
      "Iteration 1601, loss = 0.00809242\n",
      "Validation score: -0.432603\n",
      "Iteration 1602, loss = 0.00997532\n",
      "Validation score: -0.417641\n",
      "Iteration 1603, loss = 0.00830181\n",
      "Validation score: -0.394319\n",
      "Iteration 1604, loss = 0.00666865\n",
      "Validation score: -0.406408\n",
      "Iteration 1605, loss = 0.00916118\n",
      "Validation score: -0.395652\n",
      "Iteration 1606, loss = 0.00699073\n",
      "Validation score: -0.404894\n",
      "Iteration 1607, loss = 0.01020094\n",
      "Validation score: -0.416716\n",
      "Iteration 1608, loss = 0.00726815\n",
      "Validation score: -0.398787\n",
      "Iteration 1609, loss = 0.00983443\n",
      "Validation score: -0.391822\n",
      "Iteration 1610, loss = 0.01335828\n",
      "Validation score: -0.400365\n",
      "Iteration 1611, loss = 0.00898445\n",
      "Validation score: -0.452978\n",
      "Iteration 1612, loss = 0.01196171\n",
      "Validation score: -0.431857\n",
      "Iteration 1613, loss = 0.00690976\n",
      "Validation score: -0.414581\n",
      "Iteration 1614, loss = 0.01591525\n",
      "Validation score: -0.385475\n",
      "Iteration 1615, loss = 0.01939602\n",
      "Validation score: -0.476622\n",
      "Iteration 1616, loss = 0.01316285\n",
      "Validation score: -0.477791\n",
      "Iteration 1617, loss = 0.00771193\n",
      "Validation score: -0.460003\n",
      "Iteration 1618, loss = 0.01258739\n",
      "Validation score: -0.455119\n",
      "Iteration 1619, loss = 0.01230850\n",
      "Validation score: -0.417131\n",
      "Iteration 1620, loss = 0.00803959\n",
      "Validation score: -0.445161\n",
      "Iteration 1621, loss = 0.00838334\n",
      "Validation score: -0.411037\n",
      "Iteration 1622, loss = 0.00896967\n",
      "Validation score: -0.403957\n",
      "Iteration 1623, loss = 0.00912831\n",
      "Validation score: -0.395262\n",
      "Iteration 1624, loss = 0.00659375\n",
      "Validation score: -0.446437\n",
      "Iteration 1625, loss = 0.00850365\n",
      "Validation score: -0.451366\n",
      "Iteration 1626, loss = 0.00834267\n",
      "Validation score: -0.426666\n",
      "Iteration 1627, loss = 0.00721420\n",
      "Validation score: -0.415090\n",
      "Iteration 1628, loss = 0.00653326\n",
      "Validation score: -0.401287\n",
      "Iteration 1629, loss = 0.00665927\n",
      "Validation score: -0.413546\n",
      "Iteration 1630, loss = 0.00711876\n",
      "Validation score: -0.413230\n",
      "Iteration 1631, loss = 0.00705399\n",
      "Validation score: -0.518197\n",
      "Iteration 1632, loss = 0.01070591\n",
      "Validation score: -0.442654\n",
      "Iteration 1633, loss = 0.00746889\n",
      "Validation score: -0.428136\n",
      "Iteration 1634, loss = 0.00771763\n",
      "Validation score: -0.454909\n",
      "Iteration 1635, loss = 0.00822108\n",
      "Validation score: -0.422356\n",
      "Iteration 1636, loss = 0.00686921\n",
      "Validation score: -0.437247\n",
      "Iteration 1637, loss = 0.00751372\n",
      "Validation score: -0.431807\n",
      "Iteration 1638, loss = 0.00709119\n",
      "Validation score: -0.422379\n",
      "Iteration 1639, loss = 0.00667693\n",
      "Validation score: -0.442337\n",
      "Iteration 1640, loss = 0.00725368\n",
      "Validation score: -0.405211\n",
      "Iteration 1641, loss = 0.00699333\n",
      "Validation score: -0.404407\n",
      "Iteration 1642, loss = 0.00654945\n",
      "Validation score: -0.460436\n",
      "Iteration 1643, loss = 0.00812469\n",
      "Validation score: -0.455021\n",
      "Iteration 1644, loss = 0.00735179\n",
      "Validation score: -0.421945\n",
      "Iteration 1645, loss = 0.00680868\n",
      "Validation score: -0.411019\n",
      "Iteration 1646, loss = 0.00665147\n",
      "Validation score: -0.405279\n",
      "Iteration 1647, loss = 0.00679866\n",
      "Validation score: -0.415151\n",
      "Iteration 1648, loss = 0.00692915\n",
      "Validation score: -0.417773\n",
      "Iteration 1649, loss = 0.00648427\n",
      "Validation score: -0.415279\n",
      "Iteration 1650, loss = 0.00642954\n",
      "Validation score: -0.408325\n",
      "Iteration 1651, loss = 0.00642490\n",
      "Validation score: -0.417095\n",
      "Iteration 1652, loss = 0.00665785\n",
      "Validation score: -0.418361\n",
      "Iteration 1653, loss = 0.00645277\n",
      "Validation score: -0.419550\n",
      "Iteration 1654, loss = 0.00643960\n",
      "Validation score: -0.419365\n",
      "Iteration 1655, loss = 0.00647868\n",
      "Validation score: -0.417217\n",
      "Iteration 1656, loss = 0.00638016\n",
      "Validation score: -0.436272\n",
      "Iteration 1657, loss = 0.00677208\n",
      "Validation score: -0.424703\n",
      "Iteration 1658, loss = 0.00641846\n",
      "Validation score: -0.425131\n",
      "Iteration 1659, loss = 0.00716938\n",
      "Validation score: -0.415000\n",
      "Iteration 1660, loss = 0.00648700\n",
      "Validation score: -0.442714\n",
      "Iteration 1661, loss = 0.00803488\n",
      "Validation score: -0.429085\n",
      "Iteration 1662, loss = 0.00656898\n",
      "Validation score: -0.479621\n",
      "Iteration 1663, loss = 0.01010788\n",
      "Validation score: -0.417259\n",
      "Iteration 1664, loss = 0.00660850\n",
      "Validation score: -0.574862\n",
      "Iteration 1665, loss = 0.01587830\n",
      "Validation score: -0.431301\n",
      "Iteration 1666, loss = 0.00841674\n",
      "Validation score: -0.522090\n",
      "Iteration 1667, loss = 0.01139887\n",
      "Validation score: -0.420668\n",
      "Iteration 1668, loss = 0.00693837\n",
      "Validation score: -0.446298\n",
      "Iteration 1669, loss = 0.00902299\n",
      "Validation score: -0.420125\n",
      "Iteration 1670, loss = 0.00638265\n",
      "Validation score: -0.611937\n",
      "Iteration 1671, loss = 0.01425584\n",
      "Validation score: -0.534058\n",
      "Iteration 1672, loss = 0.00918454\n",
      "Validation score: -0.468095\n",
      "Iteration 1673, loss = 0.00911656\n",
      "Validation score: -0.890334\n",
      "Iteration 1674, loss = 0.04334672\n",
      "Validation score: -0.755572\n",
      "Iteration 1675, loss = 0.13375043\n",
      "Validation score: -0.522511\n",
      "Iteration 1676, loss = 0.01776030\n",
      "Validation score: -5.679276\n",
      "Iteration 1677, loss = 0.32895839\n",
      "Validation score: -1.023561\n",
      "Iteration 1678, loss = 0.05234465\n",
      "Validation score: -4.825961\n",
      "Iteration 1679, loss = 0.21109675\n",
      "Validation score: -3.972051\n",
      "Iteration 1680, loss = 0.15959492\n",
      "Validation score: -0.556058\n",
      "Iteration 1681, loss = 0.02322542\n",
      "Validation score: -1.529260\n",
      "Iteration 1682, loss = 0.06483208\n",
      "Validation score: -0.847334\n",
      "Iteration 1683, loss = 0.02246906\n",
      "Validation score: -0.665662\n",
      "Iteration 1684, loss = 0.02470706\n",
      "Validation score: -0.780933\n",
      "Iteration 1685, loss = 0.02007590\n",
      "Validation score: -0.694685\n",
      "Iteration 1686, loss = 0.02541102\n",
      "Validation score: -0.472412\n",
      "Iteration 1687, loss = 0.01157861\n",
      "Validation score: -0.825949\n",
      "Iteration 1688, loss = 0.01871600\n",
      "Validation score: -0.689121\n",
      "Iteration 1689, loss = 0.01690715\n",
      "Validation score: -0.596270\n",
      "Iteration 1690, loss = 0.01136411\n",
      "Validation score: -0.563353\n",
      "Iteration 1691, loss = 0.01136325\n",
      "Validation score: -0.535025\n",
      "Iteration 1692, loss = 0.01262464\n",
      "Validation score: -0.463793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1693, loss = 0.00779621\n",
      "Validation score: -0.625080\n",
      "Iteration 1694, loss = 0.01458536\n",
      "Validation score: -0.655995\n",
      "Iteration 1695, loss = 0.01444463\n",
      "Validation score: -0.441203\n",
      "Iteration 1696, loss = 0.00766710\n",
      "Validation score: -0.744141\n",
      "Iteration 1697, loss = 0.02379697\n",
      "Validation score: -0.725569\n",
      "Iteration 1698, loss = 0.01937100\n",
      "Validation score: -0.445411\n",
      "Iteration 1699, loss = 0.01768287\n",
      "Validation score: -1.004428\n",
      "Iteration 1700, loss = 0.03230967\n",
      "Validation score: -0.538959\n",
      "Iteration 1701, loss = 0.01101123\n",
      "Validation score: -0.564830\n",
      "Iteration 1702, loss = 0.01395869\n",
      "Validation score: -0.764595\n",
      "Iteration 1703, loss = 0.02584056\n",
      "Validation score: -0.520299\n",
      "Iteration 1704, loss = 0.01152936\n",
      "Validation score: -0.435497\n",
      "Iteration 1705, loss = 0.00752024\n",
      "Validation score: -0.663296\n",
      "Iteration 1706, loss = 0.01694218\n",
      "Validation score: -0.523731\n",
      "Iteration 1707, loss = 0.00846054\n",
      "Validation score: -0.449595\n",
      "Validation score did not improve more than tol=0.000000 for 1000 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=(80, 80), max_fun=150000,\n",
       "             max_iter=1000000, n_iter_no_change=1000, random_state=666,\n",
       "             tol=1e-08, verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-march",
   "metadata": {},
   "source": [
    "R2 score over the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "italian-carter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24846765502240728"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-plate",
   "metadata": {},
   "source": [
    "R2 score over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "designed-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7250019265201423"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "divided-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model.loss_curve_[10:])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-flour",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-leone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
